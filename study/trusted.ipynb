{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d03a90",
   "metadata": {},
   "source": [
    "# **Trusted** \n",
    "\n",
    "A camada trusted como a primeira representação estruturada e validada dos dados após a ingestão bruta (raw). Ela transforma arquivos heterogêneos (JSON, CSV, XML, ZIP etc.) em datasets tabulares padronizados, tipados e auditáveis, mantendo fidelidade à fonte original.\n",
    "\n",
    "***Se o Raw é evidência, a Trusted é evidência organizada.***\n",
    "\n",
    "Ela ainda não aplica regras de negócio complexas ou integra múltiplas fontes — isso pertence às camadas seguintes (Refined, Feature, etc.). A Trusted apenas garante que os dados:\n",
    "\n",
    "- possuem tipos corretos\n",
    "- têm schema estável\n",
    "- são consistentes e reprocessáveis\n",
    "- mantêm rastreabilidade completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ee168",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451206e8",
   "metadata": {},
   "source": [
    "## *BCB SGS*\n",
    "\n",
    "### *1. Tipo e Estrutura*\n",
    "Os dados extraídos da SGS são até o momento especificamente as séries SELIC (432) e IPCA (433). Por definição esses são dados diários extraídos (para IPCA o BCB aplica um interpolação para retornar o variação percentual do dia) cujo o principal interesse é *data* e *valor*. Afim de preservar uma estrutura auditável também serão gerados campos que indiquem:\n",
    "\n",
    "- Data de Processamento (injestion)\n",
    "- Arquivo Raw que gerou aquele dados\n",
    "- Hash do conteúdo para governança, pois:\n",
    "    - Auditável permitindo reconstruir histórico, provar integridade e fazer reconciliação\n",
    "    - Caso reprocesse o mesmo período os dados não são reinseridos (indepotência)\n",
    "    - Detectar alteração silenciosa (Se houver alteração de dados antigos a coluna vai acusar)\n",
    "    - Unicidade Real; Pequenas variações de campo e formatação (como tipo) não impactam a base\n",
    "\n",
    "tornando assim os dados *raw* uma *tabela clean e auditável\". Com isso em mente podemos montar o schema desses dados como:\n",
    "\n",
    "**Raw:**\n",
    " data | valor |\n",
    "|:------------:|:-------:|\n",
    "| str | str |\n",
    "\n",
    "**Trusted**\n",
    "\n",
    "| series_id | ref_date | value | raw_file | raw_hash | record_hash | ijestioningestion_ts_utc |\n",
    "|:---------:|:--------:|:-----:|:--------:|:--------:|:-----------:|:------------------------:|\n",
    "| int | date | float | str | str | str | str |\n",
    "\n",
    "series_id e ref_date fornecem naturalmente uma chave única para a base de dados.\n",
    "\n",
    "#### *Classe Modelo*\n",
    "\n",
    "Como estamos falando de um processo fixo de injestão de dados que serão transformados em arquivos *.parquet* é interessenate construir uma classe fixa de formatação de dados não dependendo de pandas. Esse tipo de arquitetura é interessante inclusive pela restrição de flexbilidade do objeto gerando flexibilidade de código, já que seu futuramente pandas não for mais uma opção o domínio SgsPoint continua o mesmo, com controle de tipo e testabilidade.\n",
    "\n",
    "```python models.py\n",
    "@dataclass(frozen=True)\n",
    "class SgsPoint:\n",
    "    series_id: int\n",
    "    ref_date: date\n",
    "    value: Optional[float]  # pode ser None se vier vazio\n",
    "    raw_file: str\n",
    "    raw_hash: str\n",
    "    record_hash: str\n",
    "    ingestion_ts_utc: str \n",
    "```\n",
    "Da mesma forma, afim de manter a escalabilidade da Base de Dados podemos já esquematizar os Metadados da séries extraídas, gerando assim maior governança dos dados e facilidade de entendimente para futuros consumidores dessa informação, tendo assim noções de fonte, nome da série, frequência de publicação, unidade sem precisar consultar documentação.\n",
    "\n",
    "```python models.py\n",
    "@dataclass(frozen=True)\n",
    "class SgsSeriesMeta:\n",
    "    series_id: int\n",
    "    name: str\n",
    "    frequency: str\n",
    "    unit: str\n",
    "    source: str = \"BCB_SGS\" # Por padrão por enquanto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfbde8",
   "metadata": {},
   "source": [
    "Apartir da forma que os arquivos JSON estão sendo salvos podemos facilmente extrair de qual série são aqueles dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60db0b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'433'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "path = Path(\"C:\\\\Users\\\\Dell\\\\OneDrive\\\\Documentos\\\\GitHub\\\\ML-ETTJ26\\\\data\\\\01_raw\\\\bcb\\\\sgs\\\\433_01-01-2000_31-12-2008.json\")\n",
    "\n",
    "stem = path.stem\n",
    "series_str = stem.split(\"_\", 1)[0]\n",
    "series_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350c2db",
   "metadata": {},
   "source": [
    "\n",
    "Com uma rápida olhada nos dados podemos perceber que as informações extaráidas da API está em uma lista de discionários onde ambas as chaves e valores são strings.\n",
    "\n",
    "```JSON\n",
    "[{'data': '01/01/2000', 'valor': '1.00'}, ...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8dcdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '01/01/2000', 'valor': '0.62'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    json_f = json.load(f)\n",
    "json_f[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c20abe",
   "metadata": {},
   "source": [
    "Antes de passar esses valores para trusted eles precisam então ser normalizados:\n",
    "- Data deve ser formato date, não string\n",
    "- Valor deve ser valor decimal com quantidade fixa de casas, não string \n",
    "\n",
    "(obs: float pode gerar comportamento indesejado em razão da base binária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9450e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2000, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "s = json_f[0][\"data\"]\n",
    "datetime.strptime(s, \"%d/%m/%Y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd3caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6200000000 0.62\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "s = json_f[0].get(\"valor\")\n",
    "s = str(s).strip()\n",
    "s = Decimal(s)\n",
    "vq = s.quantize(Decimal(\"0.0000000001\"), rounding=ROUND_HALF_UP)\n",
    "print(vq, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0e4a3",
   "metadata": {},
   "source": [
    "Tranquilamente conseguimos Gerar agora os valores hash com a segurança de comportamento maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "599d1f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'072692bcfd6ededdac1377bf9cab985900fca426ef5d8543c6d9a7cdc779fb24'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "series_id = int(series_str)\n",
    "ref_date = datetime.strptime(json_f[0][\"data\"], \"%d/%m/%Y\").date()\n",
    "value_dec = vq\n",
    "\n",
    "payload = f\"{series_id}|{ref_date.isoformat()}|{value_dec}\"\n",
    "\n",
    "record_hash = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()\n",
    "record_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f602d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2064cccd061cb5ed9f8747e42c3cbbea8637b9542f78a6146547c9c8674f67ef'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = hashlib.sha256()\n",
    "with path.open(\"rb\") as f:\n",
    "    \n",
    "    for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "        h.update(chunk)\n",
    "h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eef87fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2026-02-21T17:11:44+00:00'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "ingestion_ts_utc = datetime.now(timezone.utc).replace(microsecond=0).isoformat()\n",
    "ingestion_ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ec24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 9852 entries, 0 to 9851\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   series_id         9852 non-null   int64  \n",
      " 1   ref_date          9852 non-null   object \n",
      " 2   value             9852 non-null   float64\n",
      " 3   record_hash       9852 non-null   str    \n",
      " 4   raw_file          9852 non-null   str    \n",
      " 5   raw_hash          9852 non-null   str    \n",
      " 6   ingestion_ts_utc  9852 non-null   str    \n",
      "dtypes: float64(1), int64(1), object(1), str(4)\n",
      "memory usage: 2.2+ MB\n",
      "None\n",
      "\n",
      "raw_hash\n",
      "480c424330ea60ca1d9e880bb515e8be38bb0b61f0c3d6f6b07d640e8884bad9    3329\n",
      "023c3e8e15126a84ae1b8a9e00a325719c03eb7c8f8bbb7bf1988a81415c7926    3288\n",
      "74ec4cb5fdcd6e61a207f15f04df8b708d760c50f50e8cb4a1bd6538b7db72c6    2922\n",
      "2064cccd061cb5ed9f8747e42c3cbbea8637b9542f78a6146547c9c8674f67ef     108\n",
      "93a1f52671c819997afbd5e454898679dd21e844a227298538b613a37dae725e     108\n",
      "7a8c38a1e810ad0d8478c2962c395b58dfff765e62ade8eaddc73a51771c4f0c      97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Após rodar o pipeline da trusted ( kedro run --pipeline trusted_bcb_sgs ) podemos ler o parquet que deve ser gerado\n",
    "import pandas as pd\n",
    "\n",
    "sgs_p = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\bcb\\sgs\\points.parquet\")\n",
    "print(sgs_p.info(), sgs_p[\"raw_hash\"].value_counts(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af698c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   series_id    2 non-null      int64\n",
      " 1   series_name  2 non-null      str  \n",
      " 2   frequency    2 non-null      str  \n",
      " 3   unit         2 non-null      str  \n",
      " 4   source       2 non-null      str  \n",
      "dtypes: int64(1), str(4)\n",
      "memory usage: 244.0 bytes\n",
      "None\n",
      "\n",
      "   series_id series_name frequency    unit   source\n",
      "0        432       SELIC         D  % a.a.  BCB_SGS\n",
      "1        433        IPCA         M       %  BCB_SGS\n"
     ]
    }
   ],
   "source": [
    "sgs_m = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\bcb\\sgs\\series_meta.parquet\")\n",
    "print(sgs_m.info(), sgs_m.head(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d32fc",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc32a941",
   "metadata": {},
   "source": [
    "## *BCB DEMAB*\n",
    "\n",
    "Ao contrario do Sistema Gerenciador de Séries Temporais (SGS) do BCB o Departamento de Operações do Mercado Aberto (DEMAB) oferece os dados mensais de definitivos de Títulos Públicos Federais registrados no Sistema Especial de Liquidação e Custódia (o Selic), com detalhamento diário por título e vencimento,  ou seja, o exato insumo nescessário para construção da ETTJ PRE desse projeto.\n",
    "\n",
    "Obs: Considerarei apenas os negociados Extragrupo por considerar que as informações Intragrupo (NegT) pode gerar uma espécie de ruído de preço e liquidez desnecessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effa4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP: NegE200701.ZIP\n",
      "Counter({'.csv': 1})\n",
      "Arquivos: 1\n",
      "- NegE200701.CSV | 94.2 KB | 2007-02-03 00:04:04\n",
      "ZIP: NegE202309.ZIP\n",
      "Counter({'.csv': 1})\n",
      "Arquivos: 1\n",
      "- NegE202309.CSV | 142.7 KB | 2023-10-03 23:47:42\n",
      "ZIP: NegE202512.ZIP\n",
      "Counter({'.csv': 1})\n",
      "Arquivos: 1\n",
      "- NegE202512.CSV | 166.5 KB | 2026-01-05 23:04:18\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "zip_path = [Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\bcb\\demab\\negociacoes_titulos_federais_secundario\\NegE200701.ZIP\"), \n",
    "            Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\bcb\\demab\\negociacoes_titulos_federais_secundario\\NegE202309.ZIP\"),  \n",
    "            Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\bcb\\demab\\negociacoes_titulos_federais_secundario\\NegE202512.ZIP\"),\n",
    "            ]\n",
    "\n",
    "for zp in zip_path:\n",
    "    with zipfile.ZipFile(zp, \"r\") as z:\n",
    "        infos = z.infolist()\n",
    "        print(f\"ZIP: {zp.name}\")\n",
    "        exts = [Path(i.filename).suffix.lower() for i in z.infolist() if not i.is_dir()]\n",
    "        print(Counter(exts))\n",
    "        print(f\"Arquivos: {len(infos)}\")\n",
    "        for i in infos[:50]:\n",
    "            dt = datetime(*i.date_time)\n",
    "            print(f\"- {i.filename} | {i.file_size/1024:.1f} KB | {dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e3f8b",
   "metadata": {},
   "source": [
    "Rapidamente podemos conferir os arquivos em diferentes momentos do tempo explorando e garantido se há consistência na forma que os arquivos foram extraídos e como podemos ver, além do nome *NegEyyymm.ZIP* o arquivo compactado parece se manter o mesmo ao longo do tempo ( .csv ) sendo sempre único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d917ed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo: NegE200701.CSV\n",
      "Encoding provável: utf-8\n",
      "['DATA MOV;SIGLA;CODIGO;CODIGO ISIN;EMISSAO;VENCIMENTO;NUM DE OPER;QUANT NEGOCIADA;VALOR NEGOCIADO;PU MIN;PU MED;PU MAX;PU LASTRO;VALOR PAR;TAXA MIN;TAXA MED;TAXA MAX', '02/01/2007;LFT;210100;BRSTNCLF1741;04/01/2002;17/01/2007;28;4223;;2963,02918000;2963,02918000;2963,02918000;2962,89340793;2963,00978687;-0,0150;-0,0150;-0,0150', '02/01/2007;LFT;210100;BRSTNCLF17W8;19/09/2002;21/02/2007;2;1259;;2963,06973000;2963,07607744;2963,07694900;2962,65014685;2963,00978687;-0,0168;-0,0166;-0,0150', '02/01/2007;LFT;210100;BRSTNCLF17X6;19/09/2002;21/03/2007;43;14756;;2963,00978600;2963,09021875;2963,09125200;2962,37521180;2963,00978687;-0,0128;-0,0127;0,0000', '02/01/2007;LFT;210100;BRSTNCLF1808;19/09/2002;20/06/2007;11;12764;;2963,00978600;2963,15668471;2963,17210800;2961,64682719;2963,00978687;-0,0119;-0,0108;0,0000', '02/01/2007;LFT;210100;BRSTNCLF1832;19/09/2002;19/09/2007;4;1113;;2963,23409641;2963,23620561;2963,23646600;2960,89513416;2963,00978687;-0,0107;-0,0107;-0,0106', '02/01/2007;LFT;210100;BRSTNCLF1865;20/09/2002;19/12/2007;4;10208;;2963,00978687;2963,29982052;2963,30004800;2960,16711347;2963,00978687;-0,0102;-0,0102;0,0000', '02/01/2007;LFT;210100;BRSTNCLF1899;20/09/2002;19/03/2008;7;8461;;2963,28093300;2963,28093300;2963,28093300;2959,09556558;2963,00978687;-0,0076;-0,0076;-0,0076', '02/01/2007;LFT;210100;BRSTNCLF18C8;20/09/2002;18/06/2008;6;11053;;2967,29064080;2967,29064080;2967,29064080;2958,30818549;2963,00978687;-0,0999;-0,0999;-0,0999', '02/01/2007;LFT;210100;BRSTNCLF18F1;20/09/2002;17/09/2008;6;122;;2963,00978687;2963,58861971;2964,55334112;2957,46940448;2963,00978687;-0,0306;-0,0115;0,0000']\n",
      "Arquivo: NegE202309.CSV\n",
      "Encoding provável: utf-8\n",
      "['DATA MOV;SIGLA;CODIGO;CODIGO ISIN;EMISSAO;VENCIMENTO;NUM DE OPER;QUANT NEGOCIADA;VALOR NEGOCIADO;PU MIN;PU MED;PU MAX;PU LASTRO;VALOR PAR;TAXA MIN;TAXA MED;TAXA MAX;NUM OPER COM CORRETAGEM;QUANT NEG COM CORRETAGEM', '01/09/2023;LFT;210100;BRSTNCLF1RA8;05/01/2018;01/03/2024;37;69323;;13748,27389400;13749,10353500;13751,87601300;13743,22718972;13748,54886500;-0,0497;-0,0082;0,0043;14;16093', '01/09/2023;LFT;210100;BRSTNCLF0008;06/07/2018;01/09/2024;95;358838;;13747,86143700;13749,20258800;13822,18609200;13737,61877107;13748,54886500;-0,5368;-0,0047;0,0051;21;26026', '01/09/2023;LFT;210100;BRSTNCLF1RC4;26/10/2018;01/03/2025;72;68970;;13736,72511200;13748,23983700;13758,83277900;13730,53021963;13748,54886500;-0,0499;0,0015;0,0575;18;21016', '01/09/2023;LFT;210100;BRSTNCLF1RD2;08/03/2019;01/09/2025;131;316528;;13745,52425100;13747,35694600;13753,05838900;13723,70922581;13748,54886500;-0,0164;0,0043;0,0110;19;14820', '01/09/2023;LFT;210100;BRSTNCLF1RE0;06/09/2019;01/03/2026;135;349932;;13732,77927900;13734,35578900;13736,02393600;13706,01852313;13748,54886500;0,0366;0,0415;0,0461;22;29107', '01/09/2023;LFT;210100;BRSTNCLF1RF7;13/03/2020;01/09/2026;52;73052;;13718,54953100;13721,53956800;13744,42430000;13685,80169553;13748,54886500;0,0100;0,0657;0,0730;2;900', '01/09/2023;LFT;210100;BRSTNCLF1RG5;03/07/2020;01/03/2027;92;424191;;13688,78392400;13694,80816500;13710,38289300;13655,66387881;13748,54886500;0,0800;0,1127;0,1254;15;250810', '01/09/2023;LFT;210100;BRSTNCLF1RH3;02/07/2021;01/09/2027;57;93099;;13674,77415100;13679,48168300;13695,47946600;13634,38514234;13748,54886500;0,0970;0,1263;0,1350;5;11166', '01/09/2023;LFT;210100;BRSTNCLF1RI1;05/01/2022;01/03/2028;25;42489;;13658,53711500;13661,06151300;13662,88165700;13610,26131961;13748,54886500;0,1396;0,1426;0,1467;3;9864']\n",
      "Arquivo: NegE202512.CSV\n",
      "Encoding provável: utf-8\n",
      "['DATA MOV;SIGLA;CODIGO;CODIGO ISIN;EMISSAO;VENCIMENTO;NUM DE OPER;QUANT NEGOCIADA;VALOR NEGOCIADO;PU MIN;PU MED;PU MAX;PU LASTRO;VALOR PAR;TAXA MIN;TAXA MED;TAXA MAX;NUM OPER COM CORRETAGEM;QUANT NEG COM CORRETAGEM', '01/12/2025;LFT;210100;BRSTNCLF1RE0;06/09/2019;01/03/2026;49;293211;;17872,87366400;17876,94007800;17877,62879300;17873,48981452;17877,62879300;0,0000;0,0161;0,1099;6;8743', '01/12/2025;LFT;210100;BRSTNCLF1RF7;13/03/2020;01/09/2026;17;2232;;17877,62879300;17878,35973100;17882,40211900;17868,32504148;17877,62879300;-0,0356;-0,0053;0,0000;7;1104', '01/12/2025;LFT;210100;BRSTNCLF1RG5;03/07/2020;01/03/2027;55;114533;;17868,85087700;17871,62980600;17871,78280800;17854,15708383;17877,62879300;0,0267;0,0274;0,0401;12;3745', '01/12/2025;LFT;210100;BRSTNCLF1RH3;02/07/2021;01/09/2027;47;196126;;17849,69749300;17865,24137000;17865,79380200;17840,43330495;17877,62879300;0,0381;0,0398;0,0900;7;2158', '01/12/2025;LFT;210100;BRSTNCLF1RI1;05/01/2022;01/03/2028;36;92307;;17855,94322900;17857,28614400;17857,85613500;17825,46975799;17877,62879300;0,0496;0,0510;0,0544;5;1471', '01/12/2025;LFT;210100;BRSTNCLF1RK7;06/04/2022;01/09/2028;46;19089;;17828,26865900;17850,07897100;17851,11626900;17811,12736272;17877,62879300;0,0542;0,0563;0,1010;6;3138', '01/12/2025;LFT;210100;BRSTNCLF1RL5;05/10/2022;01/03/2029;27;38835;;17834,52582900;17835,54645500;17836,02755000;17789,82057970;17877,62879300;0,0725;0,0733;0,0751;2;7', '01/12/2025;LFT;210100;BRSTNCLF1RM3;05/07/2023;01/09/2029;43;67608;;17812,48271300;17818,55647300;17821,31427300;17767,08299158;17877,62879300;0,0847;0,0888;0,0980;5;12041', '01/12/2025;LFT;210100;BRSTNCLF1RO9;10/01/2024;01/03/2030;56;73748;;17802,23883200;17805,92413700;17817,00575300;17744,41548364;17877,62879300;0,0807;0,0955;0,1004;4;15921']\n"
     ]
    }
   ],
   "source": [
    "for zp in zip_path:\n",
    "    with zipfile.ZipFile(zp, \"r\") as z:\n",
    "        # escolha um arquivo que pareça dados\n",
    "        name = [i.filename for i in z.infolist() if i.filename.lower().endswith((\".csv\", \".txt\"))][0]\n",
    "        print(\"Arquivo:\", name)\n",
    "        with z.open(name) as f:\n",
    "            sample = f.read(4096)  # 4KB\n",
    "        # tente decodificar\n",
    "        for enc in (\"utf-8\", \"latin-1\", \"cp1252\"):\n",
    "            try:\n",
    "                text = sample.decode(enc)\n",
    "                print(\"Encoding provável:\", enc)\n",
    "                print(text.splitlines()[:10])\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623e96b",
   "metadata": {},
   "source": [
    "A partir daí já dá para começar a montar a trusted, pois temos que algumas colunas são fixas e tendo nas datas mais recentes com colunas a mais, irrelevantes para o modelo, mas interessante se atentar na hora de modelar o fluxo para a trusted. Assim como com os dados de SGS podemos já estruturar os dados:\n",
    "\n",
    "**Raw:** Temos muitas colunas que vão apenas ocupar espaço e armazenar informação que nunca será usada para construção de curvas, por mais que seja interessante para analise de liquidez, por exemplo, por enquanto são desnescessárias e não serão carregadas na trusted.\n",
    "| DATA MOV | SIGLA | CODIGO | CODIGO ISIN | EMISSAO | VENCIMENTO | NUM DE OPER | QUANT NEGOCIADA |\n",
    "|:--------:|:-----:|:------:|:-----------:|:-------:|:----------:|:-----------:|:---------------:|\n",
    "\n",
    "| PU MIN | PU MED | PU MAX | PU LASTRO | VALOR PAR | TAXA MIN | TAXA MED | TAXA MAX | OPER COM CORRETAGEM | QUANT NEG COM CORRETAGEM |\n",
    "| :------:|:------:|:------:|:---------:|:---------:|:--------:|:-------:|:--------:|:-------------------:|:------------------------:|\n",
    "\n",
    "**Trusted:**\n",
    "| DATA MOV | SIGLA | CODIGO ISIN | EMISSAO | VENCIMENTO | PU MIN | PU MED | PU MAX | PU LASTRO | VALOR PAR | TAXA MIN | TAXA MED | TAXA MAX |\n",
    "|:--------:|:-----:|:-----------:|:-------:|:----------:|:------:|:------:|:------:|:---------:|:---------:|:--------:|:--------:|:--------:|\n",
    "\n",
    "Já aqui podemos podemos fazer a separação por fato e dimensão e construir os modelos de domínio\n",
    "\n",
    "```python models.py\n",
    "@dataclass(frozen=True)\n",
    "class DemabQuoteDaily:\n",
    "    trade_date: date\n",
    "    codigo_isin: str\n",
    "\n",
    "    pu_min: Optional[float]\n",
    "    pu_med: Optional[float]\n",
    "    pu_max: Optional[float]\n",
    "    pu_lastro: Optional[float] \n",
    "    valor_par : Optional[float]\n",
    "\n",
    "    taxa_min: Optional[float]\n",
    "    taxa_med: Optional[float]\n",
    "    taxa_max: Optional[float]\n",
    "\n",
    "    ref_month: str\n",
    "    raw_zip_file: str\n",
    "    raw_zip_hash: str\n",
    "    inner_file: str\n",
    "    record_hash: str\n",
    "    ingestion_ts_utc: str \n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DemabInstrument:\n",
    "    codigo_isin: str\n",
    "    sigla: str\n",
    "    emissao_date: date\n",
    "    vencimento_date: date\n",
    "    source: str = \"BCB_DEMAB\" # Por padrão por enquanto\n",
    "```\n",
    "onde record_hash será montada por : isin | trade_date | pu_med | taxa_med\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f3f878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 746 entries, 0 to 745\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   trade_date        746 non-null    object \n",
      " 1   isin              746 non-null    str    \n",
      " 2   pu_min            658 non-null    float64\n",
      " 3   pu_med            658 non-null    float64\n",
      " 4   pu_max            658 non-null    float64\n",
      " 5   pu_lastro         746 non-null    float64\n",
      " 6   valor_par         746 non-null    float64\n",
      " 7   taxa_min          425 non-null    float64\n",
      " 8   taxa_med          425 non-null    float64\n",
      " 9   taxa_max          425 non-null    float64\n",
      " 10  raw_zip_file      746 non-null    str    \n",
      " 11  raw_zip_hash      746 non-null    str    \n",
      " 12  inner_file        746 non-null    str    \n",
      " 13  record_hash       746 non-null    str    \n",
      " 14  ingestion_ts_utc  746 non-null    str    \n",
      "dtypes: float64(8), object(1), str(6)\n",
      "memory usage: 228.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\bcb\\demab\\quotes_daily\\2008-08.parquet\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b401b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2008, 8, 1), datetime.date(2008, 8, 4),\n",
       "       datetime.date(2008, 8, 5), datetime.date(2008, 8, 6),\n",
       "       datetime.date(2008, 8, 7), datetime.date(2008, 8, 8),\n",
       "       datetime.date(2008, 8, 11), datetime.date(2008, 8, 12),\n",
       "       datetime.date(2008, 8, 13), datetime.date(2008, 8, 14),\n",
       "       datetime.date(2008, 8, 15), datetime.date(2008, 8, 18),\n",
       "       datetime.date(2008, 8, 19), datetime.date(2008, 8, 20),\n",
       "       datetime.date(2008, 8, 21), datetime.date(2008, 8, 22),\n",
       "       datetime.date(2008, 8, 25), datetime.date(2008, 8, 26),\n",
       "       datetime.date(2008, 8, 27), datetime.date(2008, 8, 28),\n",
       "       datetime.date(2008, 8, 29)], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"pu_med\"].isna() & df[\"taxa_med\"].isna()][\"trade_date\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02199c6",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f673027",
   "metadata": {},
   "source": [
    "## *B3 Price Report*\n",
    "Assim como no DEMAB os arquvios B3 são zipados, porém agora cada arquivo representa a extração de um dia. Price Report especificamente contém o relatório completo detalhado por dia do pregão. A decisão de usar esse price report para capturar as negociações de futuro de DI ao invés do simplificado é por conta quantidade de dados históricos disponíveis, já que apenas recentemente começaram a separar o mercado de ações e derivativos em dois reports simplificados distintos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df6c3409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP: PR200102_20200102.zip\n",
      "Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR200102.zip | 2417.4 KB | 2026-02-15 23:40:14\n",
      "ZIP: PR220517_20220517.zip\n",
      "Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR220517.zip | 4915.4 KB | 2026-02-16 00:00:10\n",
      "ZIP: PR260204_20260204.zip\n",
      "Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR260204.zip | 8040.9 KB | 2026-02-16 01:10:10\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "zip_path = [Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\b3\\PriceReport\\PR200102_20200102.zip\"), \n",
    "            Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\b3\\PriceReport\\PR220517_20220517.zip\"),  \n",
    "            Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\b3\\PriceReport\\PR260204_20260204.zip\"),\n",
    "            ]\n",
    "\n",
    "for zp in zip_path:\n",
    "    with zipfile.ZipFile(zp, \"r\") as z:\n",
    "        infos = z.infolist()\n",
    "        print(f\"ZIP: {zp.name}\")\n",
    "        exts = [Path(i.filename).suffix.lower() for i in z.infolist() if not i.is_dir()]\n",
    "        print(Counter(exts))\n",
    "        print(f\"Arquivos: {len(infos)}\")\n",
    "        for i in infos[:50]:\n",
    "            dt = datetime(*i.date_time)\n",
    "            print(f\"- {i.filename} | {i.file_size/1024:.1f} KB | {dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48bb5d7",
   "metadata": {},
   "source": [
    "Muito interessante observar que há dentro de cada arquivo compactado um arquivo compactado ( .zip ) também, isso mostra a nescessidade de fazer segunda abertura de zip para investigar. Olhando então mais afundo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd8aecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ZIP EXTERNO: PR200102_20200102.zip\n",
      "Extensões: Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR200102.zip | 2417.4 KB | 2026-02-15 23:40:14\n",
      "\n",
      "  >>> Abrindo ZIP interno: PR200102.zip\n",
      "  Extensões internas: Counter({'.xml': 3})\n",
      "  Arquivos internos: 3\n",
      "   - BVBG.086.01_BV000328202001020328000001830098585.xml | 35566.1 KB | 2020-01-02 18:30:50\n",
      "   - BVBG.086.01_BV000328202001020328000001900552975.xml | 35650.7 KB | 2020-01-02 19:01:34\n",
      "   - BVBG.086.01_BV000328202001020328000001952035761.xml | 35658.0 KB | 2020-01-02 19:52:44\n",
      "\n",
      "ZIP EXTERNO: PR220517_20220517.zip\n",
      "Extensões: Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR220517.zip | 4915.4 KB | 2026-02-16 00:00:10\n",
      "\n",
      "  >>> Abrindo ZIP interno: PR220517.zip\n",
      "  Extensões internas: Counter({'.xml': 3})\n",
      "  Arquivos internos: 3\n",
      "   - BVBG.086.01_BV000328202205170328000001809111380.xml | 66746.0 KB | 2022-05-17 18:10:08\n",
      "   - BVBG.086.01_BV000328202205170328000001858502601.xml | 66760.4 KB | 2022-05-17 18:59:38\n",
      "   - BVBG.086.01_BV000328202205170328000001922141813.xml | 66760.4 KB | 2022-05-17 19:23:22\n",
      "\n",
      "ZIP EXTERNO: PR260204_20260204.zip\n",
      "Extensões: Counter({'.zip': 1})\n",
      "Arquivos: 1\n",
      "- PR260204.zip | 8040.9 KB | 2026-02-16 01:10:10\n",
      "\n",
      "  >>> Abrindo ZIP interno: PR260204.zip\n",
      "  Extensões internas: Counter({'.xml': 3})\n",
      "  Arquivos internos: 3\n",
      "   - BVBG.086.01_BV000328202602040328000001849188859.xml | 112042.9 KB | 2026-02-04 18:50:46\n",
      "   - BVBG.086.01_BV000328202602040328000001914114854.xml | 112049.0 KB | 2026-02-04 19:15:36\n",
      "   - BVBG.086.01_BV000328202602040328000001945385434.xml | 112062.6 KB | 2026-02-04 19:47:06\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "\n",
    "for zp in zip_path:\n",
    "    with zipfile.ZipFile(zp, \"r\") as z:\n",
    "        infos = z.infolist()\n",
    "        print(f\"\\nZIP EXTERNO: {zp.name}\")\n",
    "        \n",
    "        exts = [Path(i.filename).suffix.lower() \n",
    "                for i in infos if not i.is_dir()]\n",
    "        print(\"Extensões:\", Counter(exts))\n",
    "        print(f\"Arquivos: {len(infos)}\")\n",
    "\n",
    "        for i in infos:\n",
    "            dt = datetime(*i.date_time)\n",
    "            print(f\"- {i.filename} | {i.file_size/1024:.1f} KB | {dt}\")\n",
    "\n",
    "            # Se for um ZIP interno, abrir na memória\n",
    "            if i.filename.lower().endswith(\".zip\"):\n",
    "                print(f\"\\n  >>> Abrindo ZIP interno: {i.filename}\")\n",
    "\n",
    "                with z.open(i) as inner_file:\n",
    "                    inner_bytes = BytesIO(inner_file.read())\n",
    "\n",
    "                    with zipfile.ZipFile(inner_bytes, \"r\") as inner_zip:\n",
    "                        inner_infos = inner_zip.infolist()\n",
    "                        inner_exts = [\n",
    "                            Path(j.filename).suffix.lower()\n",
    "                            for j in inner_infos if not j.is_dir()\n",
    "                        ]\n",
    "\n",
    "                        print(\"  Extensões internas:\", Counter(inner_exts))\n",
    "                        print(f\"  Arquivos internos: {len(inner_infos)}\")\n",
    "\n",
    "                        for j in inner_infos[:20]:\n",
    "                            dt2 = datetime(*j.date_time)\n",
    "                            print(f\"   - {j.filename} | {j.file_size/1024:.1f} KB | {dt2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd821a",
   "metadata": {},
   "source": [
    "Veja então que consistentemente cada arquivo compactado possui um único arquivo .zip que por sua vez possue 3 arquivos .xml dentro de si. Pela quantidade de arquivos (Estou rodando desde 01/01/2020) é inteligente começar a montar uma estratégia que não carregue (ou carregue o mínimo)desses arquivos na memória e salve apenas o nescessário. Antes disso precisamos garantir nesse processo 2 coisas: Os arquivos intradiários possuem a mesma estrutura; Ao longo do tempo sempre temos o mesmo esquema de infromações.\n",
    "\n",
    "Como essa infraestrutura apenas dá suporte ao projeto principal considerarei que o arquivo mais recente dentre os 3 do dia possui a informação oficial de mercado sobre os produtos já consolidado e apenas criarei um traffic light system para compará-los e ascender um alerta no caso de informações muito discrepantes, não havendo assim problemas de versões ou viéses que devem ser tratados na engenharia de dados. \n",
    "\n",
    "Analizando as primeiros 5000 bytes do arquivo vemos que:\n",
    "\n",
    "- **1° ) A Raiz e o Schema ( XSD )**\n",
    "    ```html\n",
    "    <Document ... xsi:schemaLocation=\"urn:bvmf.052.01.xsd bvmf.052.01.xsd\" xmlns=\"urn:bvmf.052.01.xsd\">\n",
    "    ```\n",
    "    O documento segue o namespace \"urn:bvmf.052.01.xsd\" e existe um schemalocation dizendo qual xsd define esse envelope\n",
    "\n",
    "- **2° ) Header do Arquivo ( Metadado )**\n",
    "    ```html\n",
    "    <BizFileHdr> ... <BizGrpIdr> ... <TtlNbOfMsg>15990</TtlNbOfMsg\\> ...\n",
    "    ```\n",
    "    ID do grupo/lote ( BizGrpId ); Número total de mensagens ( TtlNbOfMsg ) é por volta de ~15k; tipo do grupo (BizGrpTp = BVBG.086.01); e data de criação\n",
    "\n",
    "- **3° ) Estrutura Envelope + Conteúdo ( ISO20022 )**\n",
    "    ```html\n",
    "    <AppHdr xmlns=\"urn:iso:std:iso:20022:tech:xsd:head.001.001.01\">\n",
    "    <Document xmlns=\"urn:bvmf.217.01.xsd\">\n",
    "      <PricRpt> ...\n",
    "    ```\n",
    "\n",
    "    Com isso já conseguimos acelerar um search prático na captura de dados que ignore o envelope ( bvmf.052.01 ) e passe diretamente para o bloco de informações PricRpt do payload ( bvmf.217.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "681ebaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<Document xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"urn:bvmf.052.01.xsd bvmf.052.01.xsd\" xmlns=\"urn:bvmf.052.01.xsd\">\n",
      "  <BizFileHdr>\n",
      "    <Xchg>\n",
      "      <BizGrpDesc>\n",
      "        <Fr>\n",
      "          <OrgId>\n",
      "            <Id>\n",
      "              <OrgId>\n",
      "                <Othr>\n",
      "                  <Id>BVMF</Id>\n",
      "                  <Issr>40</Issr>\n",
      "                  <SchmeNm>\n",
      "                    <Prtry>39</Prtry>\n",
      "                  </SchmeNm>\n",
      "                </Othr>\n",
      "              </OrgId>\n",
      "            </Id>\n",
      "          </OrgId>\n",
      "        </Fr>\n",
      "        <To>\n",
      "          <OrgId>\n",
      "            <Id>\n",
      "              <OrgId>\n",
      "                <Othr>\n",
      "                  <Id>PUBLIC</Id>\n",
      "                  <Issr>40</Issr>\n",
      "                  <SchmeNm>\n",
      "                    <Prtry>39</Prtry>\n",
      "                  </SchmeNm>\n",
      "                </Othr>\n",
      "              </OrgId>\n",
      "            </Id>\n",
      "          </OrgId>\n",
      "        </To>\n",
      "        <BizGrpDtls>\n",
      "          <BizGrpIdr>BV000328202001020328000001830040455</BizGrpIdr>\n",
      "          <TtlNbOfMsg>15990</TtlNbOfMsg>\n",
      "          <BizGrpTp>BVBG.086.01</BizGrpTp>\n",
      "          <CreDtAndTm>2020-01-02T18:30:04</CreDtAndTm>\n",
      "        </BizGrpDtls>\n",
      "        <MsgTpDef>\n",
      "          <MsgDefIdr>BVMF.217.01</MsgDefIdr>\n",
      "          <NbOfMsg>15990</NbOfMsg>\n",
      "        </MsgTpDef>\n",
      "      </BizGrpDesc>\n",
      "      <BizGrp>\n",
      "        <AppHdr xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:iso:std:iso:20022:tech:xsd:head.001.001.01\">\n",
      "          <BizMsgIdr>BV000328202001020328000001830040455</BizMsgIdr>\n",
      "          <MsgDefIdr>BVMF.217.01</MsgDefIdr>\n",
      "          <CreDt>2020-01-02T21:30:04Z</CreDt>\n",
      "          <Fr>\n",
      "            <OrgId>\n",
      "              <Id>\n",
      "                <OrgId>\n",
      "                  <Othr>\n",
      "                    <Id>BVMF</Id>\n",
      "                    <SchmeNm>\n",
      "                      <Prtry>39</Prtry>\n",
      "                    </SchmeNm>\n",
      "                    <Issr>40</Issr>\n",
      "                  </Othr>\n",
      "                </OrgId>\n",
      "              </Id>\n",
      "            </OrgId>\n",
      "          </Fr>\n",
      "          <To>\n",
      "            <OrgId>\n",
      "              <Id>\n",
      "                <OrgId>\n",
      "                  <Othr>\n",
      "                    <Id>PUBLIC</Id>\n",
      "                    <SchmeNm>\n",
      "                      <Prtry>39</Prtry>\n",
      "                    </SchmeNm>\n",
      "                    <Issr>40</Issr>\n",
      "                  </Othr>\n",
      "                </OrgId>\n",
      "              </Id>\n",
      "            </OrgId>\n",
      "          </To>\n",
      "        </AppHdr>\n",
      "        <Document xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:bvmf.217.01.xsd\">\n",
      "          <PricRpt>\n",
      "            <TradDt>\n",
      "              <Dt>2020-01-02</Dt>\n",
      "            </TradDt>\n",
      "            <SctyId>\n",
      "              <TckrSymb>IDIJ20P282800</TckrSymb>\n",
      "            </SctyId>\n",
      "            <FinInstrmId>\n",
      "              <OthrId>\n",
      "                <Id>200000270875</Id>\n",
      "                <Tp>\n",
      "                  <Prtry>8</Prtry>\n",
      "                </Tp>\n",
      "              </OthrId>\n",
      "              <PlcOfListg>\n",
      "                <MktIdrCd>BVMF</MktIdrCd>\n",
      "              </PlcOfListg>\n",
      "            </FinInstrmId>\n",
      "            <TradDtls />\n",
      "            <FinInstrmAttrbts>\n",
      "              <OpnIntrst>1028000</OpnIntrst>\n",
      "              <MaxTradLmt Ccy=\"BRL\">99999.01</MaxTradLmt>\n",
      "              <MinTradLmt Ccy=\"BRL\">0.01</MinTradLmt>\n",
      "            </FinInstrmAttrbts>\n",
      "          </PricRpt>\n",
      "        </Document>\n",
      "      </BizGrp>\n",
      "      <BizGrp>\n",
      "        <AppHdr xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:iso:std:iso:20022:tech:xsd:head.001.001.01\">\n",
      "          <BizMsgIdr>BV000328202001020328000001830040455</BizMsgIdr>\n",
      "          <MsgDefIdr>BVMF.217.01</MsgDefIdr>\n",
      "          <CreDt>2020-01-02T21:30:04Z</CreDt>\n",
      "          <Fr>\n",
      "            <OrgId>\n",
      "              <Id>\n",
      "                <OrgId>\n",
      "                  <Othr>\n",
      "                    <Id>BVMF</Id>\n",
      "                    <SchmeNm>\n",
      "                      <Prtry>39</Prtry>\n",
      "                    </SchmeNm>\n",
      "                    <Issr>40</Issr>\n",
      "                  </Othr>\n",
      "                </OrgId>\n",
      "              </Id>\n",
      "            </OrgId>\n",
      "          </Fr>\n",
      "          <To>\n",
      "            <OrgId>\n",
      "              <Id>\n",
      "                <OrgId>\n",
      "                  <Othr>\n",
      "                    <Id>PUBLIC</Id>\n",
      "                    <SchmeNm>\n",
      "                      <Prtry>39</Prtry>\n",
      "                    </SchmeNm>\n",
      "                    <Issr>40</Issr>\n",
      "                  </Othr>\n",
      "                </OrgId>\n",
      "              </Id>\n",
      "            </OrgId>\n",
      "          </To>\n",
      "        </AppHdr>\n",
      "        <Document xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:bvmf.217.01.xsd\">\n",
      "          <PricRpt>\n",
      "            <TradDt>\n",
      "              <Dt>2020-01-02</Dt>\n",
      "            </TradDt>\n",
      "            <SctyI\n"
     ]
    }
   ],
   "source": [
    "zip_externo = zip_path[0]\n",
    "with zipfile.ZipFile(zip_externo, \"r\") as z:\n",
    "    inner_name = [n for n in z.namelist() if n.lower().endswith(\".zip\")][0]\n",
    "    inner_bytes = BytesIO(z.read(inner_name))\n",
    "\n",
    "with zipfile.ZipFile(inner_bytes, \"r\") as zi:\n",
    "    xml_name = [n for n in zi.namelist() if n.lower().endswith(\".xml\")][0]\n",
    "    with zi.open(xml_name) as f:\n",
    "        print(f.read(5000).decode(\"utf-8\", errors=\"replace\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483521e",
   "metadata": {},
   "source": [
    "Dando segmento ao plano, aqui investigamos as mudanças estruturais dos arquivos intradiário (Os 3 XMLs do ZIP) e interdiário (entre as 3 datas esolhida). Montei em formato de função para ter liberdade de escolher mais datas para analisar, a profundidade de análise e PrcRprt em cada arquivo (já que o menor tem ~15k observações se não tivermos profundidade nescessária posso acabar afirmando que campos chaves deixaram de existir quando na verdade minha busca só não alcançou o produto, pois esse report cobre desde ações até derivativos e eles não possuem as mesmas propriedades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea76af0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA (ZIP EXTERNO): PR200102_20200102.zip\n",
      "XMLs encontrados: 3 -> ['BVBG.086.01_BV000328202001020328000001830098585.xml', 'BVBG.086.01_BV000328202001020328000001900552975.xml', 'BVBG.086.01_BV000328202001020328000001952035761.xml']\n",
      "Namespaces (união): 3\n",
      "Paths (união): 43\n",
      "TradDtls stats: {'TradDtls_empty': 11473, 'TradDtls_present': 3527}\n",
      "\n",
      "--- Diferenças INTRA-DIA (pares) ---\n",
      "BVBG.086.01_BV000328202001020328000001830098585.xml vs BVBG.086.01_BV000328202001020328000001900552975.xml: paths only_in_left=0, only_in_right=0 | common=43\n",
      "BVBG.086.01_BV000328202001020328000001830098585.xml vs BVBG.086.01_BV000328202001020328000001952035761.xml: paths only_in_left=0, only_in_right=0 | common=43\n",
      "BVBG.086.01_BV000328202001020328000001900552975.xml vs BVBG.086.01_BV000328202001020328000001952035761.xml: paths only_in_left=0, only_in_right=0 | common=43\n",
      "\n",
      "================================================================================\n",
      "DATA (ZIP EXTERNO): PR220517_20220517.zip\n",
      "XMLs encontrados: 3 -> ['BVBG.086.01_BV000328202205170328000001809111380.xml', 'BVBG.086.01_BV000328202205170328000001858502601.xml', 'BVBG.086.01_BV000328202205170328000001922141813.xml']\n",
      "Namespaces (união): 3\n",
      "Paths (união): 47\n",
      "TradDtls stats: {'TradDtls_empty': 10035, 'TradDtls_present': 4965}\n",
      "\n",
      "--- Diferenças INTRA-DIA (pares) ---\n",
      "BVBG.086.01_BV000328202205170328000001809111380.xml vs BVBG.086.01_BV000328202205170328000001858502601.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "BVBG.086.01_BV000328202205170328000001809111380.xml vs BVBG.086.01_BV000328202205170328000001922141813.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "BVBG.086.01_BV000328202205170328000001858502601.xml vs BVBG.086.01_BV000328202205170328000001922141813.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "\n",
      "================================================================================\n",
      "DATA (ZIP EXTERNO): PR260204_20260204.zip\n",
      "XMLs encontrados: 3 -> ['BVBG.086.01_BV000328202602040328000001849188859.xml', 'BVBG.086.01_BV000328202602040328000001914114854.xml', 'BVBG.086.01_BV000328202602040328000001945385434.xml']\n",
      "Namespaces (união): 3\n",
      "Paths (união): 47\n",
      "TradDtls stats: {'TradDtls_empty': 9966, 'TradDtls_present': 5034}\n",
      "\n",
      "--- Diferenças INTRA-DIA (pares) ---\n",
      "BVBG.086.01_BV000328202602040328000001849188859.xml vs BVBG.086.01_BV000328202602040328000001914114854.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "BVBG.086.01_BV000328202602040328000001849188859.xml vs BVBG.086.01_BV000328202602040328000001945385434.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "BVBG.086.01_BV000328202602040328000001914114854.xml vs BVBG.086.01_BV000328202602040328000001945385434.xml: paths only_in_left=0, only_in_right=0 | common=47\n",
      "\n",
      "================================================================================\n",
      "COMPARAÇÃO ENTRE DATAS (fingerprint agregado por dia)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PR200102_20200102.zip  VS  PR220517_20220517.zip\n",
      "Namespaces: only_in_PR200102_20200102.zip=0, only_in_PR220517_20220517.zip=0, common=3\n",
      "Paths: only_in_PR200102_20200102.zip=0, only_in_PR220517_20220517.zip=4, common=43\n",
      "Exemplos only_in_a: []\n",
      "Exemplos only_in_b: ['FinInstrmAttrbts/IntlNonRglrVol', 'FinInstrmAttrbts/NonRglrTraddCtrcts', 'FinInstrmAttrbts/NonRglrTxsQty', 'FinInstrmAttrbts/NtlNonRglrVol']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PR200102_20200102.zip  VS  PR260204_20260204.zip\n",
      "Namespaces: only_in_PR200102_20200102.zip=0, only_in_PR260204_20260204.zip=0, common=3\n",
      "Paths: only_in_PR200102_20200102.zip=0, only_in_PR260204_20260204.zip=4, common=43\n",
      "Exemplos only_in_a: []\n",
      "Exemplos only_in_b: ['FinInstrmAttrbts/IntlNonRglrVol', 'FinInstrmAttrbts/NonRglrTraddCtrcts', 'FinInstrmAttrbts/NonRglrTxsQty', 'FinInstrmAttrbts/NtlNonRglrVol']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PR220517_20220517.zip  VS  PR260204_20260204.zip\n",
      "Namespaces: only_in_PR220517_20220517.zip=0, only_in_PR260204_20260204.zip=0, common=3\n",
      "Paths: only_in_PR220517_20220517.zip=0, only_in_PR260204_20260204.zip=0, common=47\n",
      "Exemplos only_in_a: []\n",
      "Exemplos only_in_b: []\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers de XML / fingerprint\n",
    "# -----------------------------\n",
    "\n",
    "def strip_ns(tag: str) -> str:\n",
    "    return tag.split(\"}\", 1)[-1] if \"}\" in tag else tag\n",
    "\n",
    "def fingerprint_price_report(xml_file, max_pricrpt=300, max_depth=5):\n",
    "    \"\"\"\n",
    "    Fingerprint estrutural do XML (sem valores), focado em PricRpt:\n",
    "      - namespaces vistos\n",
    "      - qtde PricRpt escaneados (até max_pricrpt)\n",
    "      - conjunto de paths relativos dentro de PricRpt (até max_depth)\n",
    "      - presença/ausência de TradDtls (missing/present/empty)\n",
    "    \"\"\"\n",
    "    ns_seen = set()\n",
    "    pricrpt_count = 0\n",
    "    paths = set()\n",
    "    block_presence = Counter()\n",
    "\n",
    "    ctx = ET.iterparse(xml_file, events=(\"start\", \"end\"))\n",
    "\n",
    "    stack = []\n",
    "    in_pricrpt = False\n",
    "    pricrpt_depth0 = None\n",
    "    current_pricrpt_has_traddtls = False\n",
    "\n",
    "    for event, elem in ctx:\n",
    "        tag_full = elem.tag\n",
    "        tag = strip_ns(tag_full)\n",
    "\n",
    "        # registra namespaces (forma {ns}Tag)\n",
    "        if \"}\" in tag_full:\n",
    "            ns_seen.add(tag_full.split(\"}\", 1)[0][1:])\n",
    "\n",
    "        if event == \"start\":\n",
    "            stack.append(tag)\n",
    "\n",
    "            if tag == \"PricRpt\":\n",
    "                in_pricrpt = True\n",
    "                pricrpt_depth0 = len(stack)\n",
    "                current_pricrpt_has_traddtls = False\n",
    "\n",
    "        else:  # end\n",
    "            if in_pricrpt:\n",
    "                rel_stack = stack[pricrpt_depth0:]  # começa dentro de PricRpt\n",
    "                if 1 <= len(rel_stack) <= max_depth:\n",
    "                    paths.add(\"/\".join(rel_stack))\n",
    "\n",
    "                if tag == \"TradDtls\":\n",
    "                    # TradDtls pode existir mas vir vazio\n",
    "                    if len(list(elem)) == 0 and not ((elem.text or \"\").strip()):\n",
    "                        block_presence[\"TradDtls_empty\"] += 1\n",
    "                    else:\n",
    "                        block_presence[\"TradDtls_present\"] += 1\n",
    "                    current_pricrpt_has_traddtls = True\n",
    "\n",
    "                if tag == \"PricRpt\":\n",
    "                    pricrpt_count += 1\n",
    "                    if not current_pricrpt_has_traddtls:\n",
    "                        block_presence[\"TradDtls_missing\"] += 1\n",
    "\n",
    "                    # libera memória\n",
    "                    elem.clear()\n",
    "                    in_pricrpt = False\n",
    "                    pricrpt_depth0 = None\n",
    "\n",
    "                    if pricrpt_count >= max_pricrpt:\n",
    "                        break\n",
    "\n",
    "            stack.pop()\n",
    "\n",
    "    return {\n",
    "        \"namespaces\": ns_seen,\n",
    "        \"paths\": paths,\n",
    "        \"block_presence\": dict(block_presence),\n",
    "        \"pricrpt_count_scanned\": pricrpt_count,\n",
    "    }\n",
    "\n",
    "def diff_sets(a: set, b: set):\n",
    "    return {\n",
    "        \"only_in_a\": sorted(a - b),\n",
    "        \"only_in_b\": sorted(b - a),\n",
    "        \"common\": len(a & b),\n",
    "        \"size_a\": len(a),\n",
    "        \"size_b\": len(b),\n",
    "    }\n",
    "\n",
    "def compare_fps(fp_items):\n",
    "    \"\"\"\n",
    "    fp_items = [(label, fp_dict), ...]\n",
    "    Compara todos os pares e retorna um dict com diffs.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for i in range(len(fp_items)):\n",
    "        for j in range(i + 1, len(fp_items)):\n",
    "            li, fpi = fp_items[i]\n",
    "            lj, fpj = fp_items[j]\n",
    "            out[f\"{li} vs {lj}\"] = {\n",
    "                \"namespaces\": diff_sets(set(fpi[\"namespaces\"]), set(fpj[\"namespaces\"])),\n",
    "                \"paths\": diff_sets(set(fpi[\"paths\"]), set(fpj[\"paths\"])),\n",
    "                \"block_presence_left\": fpi[\"block_presence\"],\n",
    "                \"block_presence_right\": fpj[\"block_presence\"],\n",
    "                \"pricrpt_scanned_left\": fpi[\"pricrpt_count_scanned\"],\n",
    "                \"pricrpt_scanned_right\": fpj[\"pricrpt_count_scanned\"],\n",
    "            }\n",
    "    return out\n",
    "\n",
    "def merge_day_fps(fp_items_for_day):\n",
    "    \"\"\"\n",
    "    Une os fingerprints dos 3 XMLs de um dia:\n",
    "      namespaces = união\n",
    "      paths = união\n",
    "      block_presence = soma\n",
    "    \"\"\"\n",
    "    merged_ns = set()\n",
    "    merged_paths = set()\n",
    "    merged_blocks = Counter()\n",
    "    scanned_total = 0\n",
    "\n",
    "    for label, fp in fp_items_for_day:\n",
    "        merged_ns |= set(fp[\"namespaces\"])\n",
    "        merged_paths |= set(fp[\"paths\"])\n",
    "        merged_blocks.update(fp[\"block_presence\"])\n",
    "        scanned_total += fp[\"pricrpt_count_scanned\"]\n",
    "\n",
    "    return {\n",
    "        \"namespaces\": merged_ns,\n",
    "        \"paths\": merged_paths,\n",
    "        \"block_presence\": dict(merged_blocks),\n",
    "        \"pricrpt_count_scanned_sum\": scanned_total,\n",
    "        \"files\": [label for label, _ in fp_items_for_day],\n",
    "    }\n",
    "\n",
    "# ------------------------------------------\n",
    "# Helpers para padrão de abertura de ZIP\n",
    "# ------------------------------------------\n",
    "\n",
    "def get_inner_zip_bytes(zip_externo_path: Path) -> BytesIO:\n",
    "    \"\"\"\n",
    "    Replica padrão: abre ZIP externo e pega o primeiro ZIP interno.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_externo_path, \"r\") as z:\n",
    "        inner_name = [n for n in z.namelist() if n.lower().endswith(\".zip\")][0]\n",
    "        return BytesIO(z.read(inner_name))\n",
    "\n",
    "def list_xml_names_from_inner(inner_bytes: BytesIO):\n",
    "    inner_bytes.seek(0)\n",
    "    with zipfile.ZipFile(inner_bytes, \"r\") as zi:\n",
    "        return sorted([n for n in zi.namelist() if n.lower().endswith(\".xml\")])\n",
    "\n",
    "def fingerprint_all_xmls_in_day(zip_externo_path: Path, max_pricrpt=300, max_depth=5):\n",
    "    \"\"\"\n",
    "    PASSO 1 (intra-dia): gera fingerprint dos 3 XMLs dentro do zip interno.\n",
    "    Retorna:\n",
    "      - lista [(xml_name, fp), ...]\n",
    "      - comparativo entre eles\n",
    "      - fingerprint agregado do dia\n",
    "    \"\"\"\n",
    "    inner_bytes = get_inner_zip_bytes(zip_externo_path)\n",
    "\n",
    "    xml_names = list_xml_names_from_inner(inner_bytes)\n",
    "    if len(xml_names) == 0:\n",
    "        raise RuntimeError(f\"Nenhum XML encontrado em {zip_externo_path.name}\")\n",
    "\n",
    "    fp_items = []\n",
    "    inner_bytes.seek(0)\n",
    "    with zipfile.ZipFile(inner_bytes, \"r\") as zi:\n",
    "        for xml_name in xml_names:\n",
    "            with zi.open(xml_name) as f:\n",
    "                fp = fingerprint_price_report(f, max_pricrpt=max_pricrpt, max_depth=max_depth)\n",
    "            fp_items.append((xml_name, fp))\n",
    "\n",
    "    intra_report = compare_fps(fp_items)\n",
    "    day_fp = merge_day_fps(fp_items)\n",
    "    return fp_items, intra_report, day_fp\n",
    "\n",
    "# -----------------------------\n",
    "# Runner: 2 passos de comparação\n",
    "# -----------------------------\n",
    "\n",
    "def run_two_step_comparison(zip_paths_for_dates, max_pricrpt=300, max_depth=5):\n",
    "    \"\"\"\n",
    "    zip_paths_for_dates: lista de Path, ex:\n",
    "      [zip_20200102, zip_20220517, zip_20260204]\n",
    "    Faz:\n",
    "      1) intra-dia: compara 3 XMLs dentro de cada data\n",
    "      2) inter-datas: compara fingerprint agregado do dia entre datas\n",
    "    \"\"\"\n",
    "    day_fps = {}  # date_label -> day_fp\n",
    "\n",
    "    # PASSO 1: intra-dia\n",
    "    for zp in zip_paths_for_dates:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"DATA (ZIP EXTERNO): {zp.name}\")\n",
    "\n",
    "        fp_items, intra_report, day_fp = fingerprint_all_xmls_in_day(\n",
    "            zp, max_pricrpt=max_pricrpt, max_depth=max_depth\n",
    "        )\n",
    "        day_fps[zp.name] = day_fp\n",
    "\n",
    "        print(f\"XMLs encontrados: {len(fp_items)} -> {[name for name, _ in fp_items]}\")\n",
    "        print(f\"Namespaces (união): {len(day_fp['namespaces'])}\")\n",
    "        print(f\"Paths (união): {len(day_fp['paths'])}\")\n",
    "        print(f\"TradDtls stats: {day_fp['block_presence']}\")\n",
    "\n",
    "        print(\"\\n--- Diferenças INTRA-DIA (pares) ---\")\n",
    "        for pair, rep in intra_report.items():\n",
    "            only_a = len(rep[\"paths\"][\"only_in_a\"])\n",
    "            only_b = len(rep[\"paths\"][\"only_in_b\"])\n",
    "            print(f\"{pair}: paths only_in_left={only_a}, only_in_right={only_b} | common={rep['paths']['common']}\")\n",
    "\n",
    "    # PASSO 2: inter-datas\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARAÇÃO ENTRE DATAS (fingerprint agregado por dia)\")\n",
    "    names = list(day_fps.keys())\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i+1, len(names)):\n",
    "            di = names[i]\n",
    "            dj = names[j]\n",
    "            fpi = day_fps[di]\n",
    "            fpj = day_fps[dj]\n",
    "            d_paths = diff_sets(set(fpi[\"paths\"]), set(fpj[\"paths\"]))\n",
    "            d_ns = diff_sets(set(fpi[\"namespaces\"]), set(fpj[\"namespaces\"]))\n",
    "\n",
    "            print(\"\\n\" + \"-\"*80)\n",
    "            print(f\"{di}  VS  {dj}\")\n",
    "            print(f\"Namespaces: only_in_{di}={len(d_ns['only_in_a'])}, only_in_{dj}={len(d_ns['only_in_b'])}, common={d_ns['common']}\")\n",
    "            print(f\"Paths: only_in_{di}={len(d_paths['only_in_a'])}, only_in_{dj}={len(d_paths['only_in_b'])}, common={d_paths['common']}\")\n",
    "\n",
    "            # Se quiser ver exatamente o que mudou (cuidado: pode ser grande)\n",
    "            print(\"Exemplos only_in_a:\", d_paths[\"only_in_a\"][:30])\n",
    "            print(\"Exemplos only_in_b:\", d_paths[\"only_in_b\"][:30])\n",
    "\n",
    "    return day_fps\n",
    "\n",
    "day_fps = run_two_step_comparison(zip_path, max_pricrpt=5000, max_depth=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316f3ca",
   "metadata": {},
   "source": [
    "Como podemos observar, ao analisar 5k observações de cada arquivo (Lembrando, se o XML de 2020 possui ~15k observações isso cobre cerca de 30% das observaçõs) já podemos tirar conclusões importantes:\n",
    "\n",
    "- Os arquivos intradiários compartilham os mesmos campos a cada observação, como podemos ver todos os 'only_in_left' e 'only_in_right' são 0 evidenciando que 2 a 2 nenhum arquivo possui mais campos descritivos que outro no mesmo dia;\n",
    "- A partir de algum momento do tempo 4 campos de informação foram adicionados, já que a quantidade de campos comuns na primeira data são 43 e nas outras duas 47;\n",
    "- Os campos que passaram a ser medidos posteriormente são:\n",
    "\n",
    "    ```python\n",
    "     ['FinInstrmAttrbts/IntlNonRglrVol', 'FinInstrmAttrbts/NonRglrTraddCtrcts', 'FinInstrmAttrbts/NonRglrTxsQty', 'FinInstrmAttrbts/NtlNonRglrVol']\n",
    "    ```\n",
    "    que são comparações estatísticas dos negociados em mercado regulado e não regulado, portanto, não impactando no projeto.\n",
    "\n",
    "Com uma busca superficial podemos ver também se para cada um dos arquivos XML $(3\\times 3 =9)$ conseguimos os mesmos tickers de DI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a673c23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtde DI1: 37\n",
      "exemplos: ['DI1G20', 'DI1U20', 'DI1N23', 'DI1J20', 'DI1F25', 'DI1X20', 'DI1V24', 'DI1J24', 'DI1F21', 'DI1F31']\n",
      "distintos: 37\n",
      "qtde DI1: 37\n",
      "exemplos: ['DI1G20', 'DI1U20', 'DI1N23', 'DI1J20', 'DI1F25', 'DI1X20', 'DI1V24', 'DI1J24', 'DI1F21', 'DI1F31']\n",
      "distintos: 37\n",
      "qtde DI1: 37\n",
      "exemplos: ['DI1G20', 'DI1U20', 'DI1N23', 'DI1J20', 'DI1F25', 'DI1X20', 'DI1V24', 'DI1J24', 'DI1F21', 'DI1F31']\n",
      "distintos: 37\n",
      "qtde DI1: 39\n",
      "exemplos: ['DI1Q22', 'DI1N23', 'DI1M22', 'DI1F25', 'DI1F35', 'DI1V24', 'DI1J24', 'DI1F31', 'DI1N26', 'DI1F29']\n",
      "distintos: 39\n",
      "qtde DI1: 39\n",
      "exemplos: ['DI1Q22', 'DI1N23', 'DI1M22', 'DI1F25', 'DI1F35', 'DI1V24', 'DI1J24', 'DI1F31', 'DI1N26', 'DI1F29']\n",
      "distintos: 39\n",
      "qtde DI1: 39\n",
      "exemplos: ['DI1Q22', 'DI1N23', 'DI1M22', 'DI1F25', 'DI1F35', 'DI1V24', 'DI1J24', 'DI1F31', 'DI1N26', 'DI1F29']\n",
      "distintos: 39\n",
      "qtde DI1: 42\n",
      "exemplos: ['DI1N26', 'DI1N29', 'DI1F34', 'DI1V27', 'DI1N31', 'DI1N28', 'DI1F27', 'DI1F37', 'DI1V26', 'DI1N30']\n",
      "distintos: 42\n",
      "qtde DI1: 42\n",
      "exemplos: ['DI1N26', 'DI1N29', 'DI1F34', 'DI1V27', 'DI1N31', 'DI1N28', 'DI1F27', 'DI1F37', 'DI1V26', 'DI1N30']\n",
      "distintos: 42\n",
      "qtde DI1: 42\n",
      "exemplos: ['DI1N26', 'DI1N29', 'DI1F34', 'DI1V27', 'DI1N31', 'DI1N28', 'DI1F27', 'DI1F37', 'DI1V26', 'DI1N30']\n",
      "distintos: 42\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def strip_ns(tag: str) -> str:\n",
    "    return tag.split(\"}\", 1)[-1] if \"}\" in tag else tag\n",
    "\n",
    "def iter_di1_tickers(xml_file):\n",
    "    \"\"\"\n",
    "    Retorna gerador de tickers que começam com DI1.\n",
    "    Não guarda o XML inteiro; vai limpando memória.\n",
    "    \"\"\"\n",
    "    ctx = ET.iterparse(xml_file, events=(\"end\",))\n",
    "    for event, elem in ctx:\n",
    "        if strip_ns(elem.tag) != \"PricRpt\":\n",
    "            continue\n",
    "\n",
    "        # acha o TckrSymb dentro desse PricRpt\n",
    "        tck = None\n",
    "        for node in elem.iter():\n",
    "            if strip_ns(node.tag) == \"TckrSymb\":\n",
    "                tck = (node.text or \"\").strip()\n",
    "                break\n",
    "\n",
    "        if tck and tck.startswith(\"DI1\"):\n",
    "            yield tck\n",
    "\n",
    "        elem.clear()\n",
    "        \n",
    "for zp in zip_path:\n",
    "    inner_bytes = get_inner_zip_bytes(zp)\n",
    "    xml_names = list_xml_names_from_inner(inner_bytes)\n",
    "    for xml_name in xml_names:\n",
    "        with zipfile.ZipFile(inner_bytes, \"r\") as zi:\n",
    "            with zi.open(xml_name) as f:\n",
    "                ticks = list(iter_di1_tickers(f))\n",
    "\n",
    "        print(\"qtde DI1:\", len(ticks))\n",
    "        print(\"exemplos:\", ticks[:10])\n",
    "        print(\"distintos:\", len(set(ticks)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7de08",
   "metadata": {},
   "source": [
    "3 a 3 podemos então afirmar que compartilham a mesma quantidade de observações únicas e inclusive as discriminam na mesma ordem ( pois as 10 últimas observações são idênticas) fortalencendo a decisão de sempre olhar para o último arquivo postado da data ao invés de desenvolver todo um processo de controle e união das 3 bases. A partir daí já podemos começar a identificar quais os campos de interesse que serão salvos no arquivo final da trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27225e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 campos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PricRpt/TradDt/Dt</td>\n",
       "      <td>2026-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PricRpt/SctyId/TckrSymb</td>\n",
       "      <td>DI1N26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PricRpt/FinInstrmId/OthrId/Id</td>\n",
       "      <td>100000103726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PricRpt/FinInstrmId/OthrId/Tp/Prtry</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PricRpt/FinInstrmId/PlcOfListg/MktIdrCd</td>\n",
       "      <td>BVMF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PricRpt/TradDtls/TradQty</td>\n",
       "      <td>3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/MktDataStrmId</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/NtlFinVol</td>\n",
       "      <td>29446304851.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/IntlFinVol</td>\n",
       "      <td>5623924225.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/OpnIntrst</td>\n",
       "      <td>4171817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/FinInstrmQty</td>\n",
       "      <td>310381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/BestBidPric</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/BestAskPric</td>\n",
       "      <td>14.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/FrstPric</td>\n",
       "      <td>14.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/MinPric</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/MaxPric</td>\n",
       "      <td>14.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/TradAvrgPric</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/LastPric</td>\n",
       "      <td>14.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/RglrTxsQty</td>\n",
       "      <td>3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/RglrTraddCtrcts</td>\n",
       "      <td>310381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/NtlRglrVol</td>\n",
       "      <td>29446304851.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/IntlRglrVol</td>\n",
       "      <td>5623924225.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/AdjstdQt</td>\n",
       "      <td>94872.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/AdjstdQtTax</td>\n",
       "      <td>14.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/AdjstdQtStin</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/PrvsAdjstdQt</td>\n",
       "      <td>94870.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/PrvsAdjstdQtTax</td>\n",
       "      <td>14.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/PrvsAdjstdQtStin</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/OscnPctg</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/VartnPts</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/AdjstdValCtrct</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/MaxTradLmt</td>\n",
       "      <td>14.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PricRpt/FinInstrmAttrbts/MinTradLmt</td>\n",
       "      <td>13.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        index               0\n",
       "0                           PricRpt/TradDt/Dt      2026-02-04\n",
       "1                     PricRpt/SctyId/TckrSymb          DI1N26\n",
       "2               PricRpt/FinInstrmId/OthrId/Id    100000103726\n",
       "3         PricRpt/FinInstrmId/OthrId/Tp/Prtry               8\n",
       "4     PricRpt/FinInstrmId/PlcOfListg/MktIdrCd            BVMF\n",
       "5                    PricRpt/TradDtls/TradQty            3484\n",
       "6      PricRpt/FinInstrmAttrbts/MktDataStrmId               E\n",
       "7          PricRpt/FinInstrmAttrbts/NtlFinVol  29446304851.57\n",
       "8         PricRpt/FinInstrmAttrbts/IntlFinVol   5623924225.36\n",
       "9          PricRpt/FinInstrmAttrbts/OpnIntrst         4171817\n",
       "10      PricRpt/FinInstrmAttrbts/FinInstrmQty          310381\n",
       "11       PricRpt/FinInstrmAttrbts/BestBidPric           14.33\n",
       "12       PricRpt/FinInstrmAttrbts/BestAskPric          14.335\n",
       "13          PricRpt/FinInstrmAttrbts/FrstPric           14.36\n",
       "14           PricRpt/FinInstrmAttrbts/MinPric           14.33\n",
       "15           PricRpt/FinInstrmAttrbts/MaxPric           14.36\n",
       "16      PricRpt/FinInstrmAttrbts/TradAvrgPric           14.34\n",
       "17          PricRpt/FinInstrmAttrbts/LastPric          14.335\n",
       "18        PricRpt/FinInstrmAttrbts/RglrTxsQty            3484\n",
       "19   PricRpt/FinInstrmAttrbts/RglrTraddCtrcts          310381\n",
       "20        PricRpt/FinInstrmAttrbts/NtlRglrVol  29446304851.57\n",
       "21       PricRpt/FinInstrmAttrbts/IntlRglrVol   5623924225.36\n",
       "22          PricRpt/FinInstrmAttrbts/AdjstdQt        94872.95\n",
       "23       PricRpt/FinInstrmAttrbts/AdjstdQtTax          14.336\n",
       "24      PricRpt/FinInstrmAttrbts/AdjstdQtStin               F\n",
       "25      PricRpt/FinInstrmAttrbts/PrvsAdjstdQt        94870.19\n",
       "26   PricRpt/FinInstrmAttrbts/PrvsAdjstdQtTax          14.344\n",
       "27  PricRpt/FinInstrmAttrbts/PrvsAdjstdQtStin               U\n",
       "28          PricRpt/FinInstrmAttrbts/OscnPctg           -0.06\n",
       "29          PricRpt/FinInstrmAttrbts/VartnPts            2.76\n",
       "30    PricRpt/FinInstrmAttrbts/AdjstdValCtrct            2.76\n",
       "31        PricRpt/FinInstrmAttrbts/MaxTradLmt           14.85\n",
       "32        PricRpt/FinInstrmAttrbts/MinTradLmt           13.85"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def strip_ns(tag: str) -> str:\n",
    "    return tag.split(\"}\", 1)[-1] if \"}\" in tag else tag\n",
    "\n",
    "def _find_first_text(elem, tag_name: str) -> str | None:\n",
    "    \"\"\"Acha o primeiro nó com tag=tag_name dentro de elem e retorna seu texto.\"\"\"\n",
    "    for n in elem.iter():\n",
    "        if strip_ns(n.tag) == tag_name:\n",
    "            txt = (n.text or \"\").strip()\n",
    "            return txt or None\n",
    "    return None\n",
    "\n",
    "def _flatten_paths(elem) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Gera um dict { \"A/B/C\": \"valor\" } para todas as folhas com texto.\n",
    "    (Sem precisar conhecer nomes de campos.)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    def walk(node, prefix=\"\"):\n",
    "        tag = strip_ns(node.tag)\n",
    "        path = f\"{prefix}/{tag}\" if prefix else tag\n",
    "\n",
    "        # se tem texto \"útil\", guarda\n",
    "        txt = (node.text or \"\").strip()\n",
    "        if txt:\n",
    "            out[path] = txt\n",
    "\n",
    "        # continua descendo\n",
    "        for ch in list(node):\n",
    "            walk(ch, path)\n",
    "\n",
    "    walk(elem, \"\")\n",
    "    return out\n",
    "\n",
    "def get_one_di1_full_pricrpt(xml_file) -> dict[str, str] | None:\n",
    "    \"\"\"\n",
    "    Encontra o primeiro <PricRpt> cujo <TckrSymb> começa com 'DI1'\n",
    "    e retorna TODOS os campos dentro desse PricRpt como {path: value}.\n",
    "    \"\"\"\n",
    "    ctx = ET.iterparse(xml_file, events=(\"end\",))\n",
    "    for _event, elem in ctx:\n",
    "        if strip_ns(elem.tag) != \"PricRpt\":\n",
    "            continue\n",
    "\n",
    "        tck = _find_first_text(elem, \"TckrSymb\")\n",
    "        if tck and tck.startswith(\"DI1\"):\n",
    "            data = _flatten_paths(elem)\n",
    "            elem.clear()\n",
    "            return data\n",
    "\n",
    "        elem.clear()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "zip_externo = zip_path[2]\n",
    "with zipfile.ZipFile(zip_externo, \"r\") as z:\n",
    "    inner_name = [n for n in z.namelist() if n.lower().endswith(\".zip\")][0]\n",
    "    inner_bytes = BytesIO(z.read(inner_name))\n",
    "\n",
    "with zipfile.ZipFile(inner_bytes, \"r\") as zi:\n",
    "    xml_name = [n for n in zi.namelist() if n.lower().endswith(\".xml\")][0]\n",
    "\n",
    "    with zi.open(xml_name) as f:\n",
    "        rec = get_one_di1_full_pricrpt(f)\n",
    "\n",
    "print(len(rec), \"campos\")\n",
    "df = pd.DataFrame.from_dict(rec, orient='index').reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e98a2dd",
   "metadata": {},
   "source": [
    "Sabendo então agora o que cada nó da árvore possui uma estrutura de campos fixo para contratos de DI Futuro podemos começar a organizar uma estratégia de informações que serão armazenadas. \n",
    "\n",
    "```python\n",
    "@dataclass(frozen=True)\n",
    "class DI1QuotesDaily:\n",
    "    # Chave Primária\n",
    "    TradDt : datetime\n",
    "    TckrSymb : str\n",
    "    snapshot_ts_utc: datetime\n",
    "\n",
    "    AdjstdQtTax : float #taxa\n",
    "    AdjstdQt : float    #pu\n",
    "    \n",
    "\n",
    "    # Info para futuros projetos\n",
    "    BestBidPric: Optional[float]\n",
    "    BestAskPric: Optional[float]\n",
    "    LastPric: Optional[float]\n",
    "    TradAvrgPric: Optional[float]\n",
    "    MinPric: Optional[float]\n",
    "    MaxPric: Optional[float]\n",
    "\n",
    "    TradQty: Optional[int]\n",
    "    FinInstrmQty: Optional[int]\n",
    "    OpnIntrst: Optional[int]\n",
    "\n",
    "    # Auditoria & Governança\n",
    "    lineage_id : str # FK\n",
    "    ingestion_ts_utc: datetime\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class InstrumentMaster:\n",
    "    # PK\n",
    "    TckrSymb : str\n",
    "\n",
    "    asset: str\n",
    "    contract_month_code: str\n",
    "    contract_year: int\n",
    "    maturity_date: datetime\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataLineage:\n",
    "    # PK\n",
    "    lineage_id : str # outer_zip|inner_zip|xml_name|snapshot_ts_utc|hash_file\n",
    "\n",
    "    outer_zip: str\n",
    "    inner_zip: str\n",
    "    xml_name: str\n",
    "    snapshot_ts_utc : str\n",
    "    hash_file: str\n",
    "    ingestion_ts_utc : datetime\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b895d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Latest snapshot: 2026-02-04 21:49:06+00:00\n",
      "New Latest snapshot: 2026-02-04 22:13:52+00:00\n",
      "New Latest snapshot: 2026-02-04 22:45:23+00:00\n"
     ]
    }
   ],
   "source": [
    "from ml_ettj26.domain.b3_PriceReport.zip_reader import NestedZipReader\n",
    "from ml_ettj26.domain.b3_PriceReport.header_probe import parse_snapshot_ts_from_head\n",
    "\n",
    "zip_externo = zip_path[2]\n",
    "zip_externo\n",
    "latest = None\n",
    "reader = NestedZipReader(zip_externo)\n",
    "latest = None\n",
    "with reader.open_inner_zip() as zi:\n",
    "    xmls = [n for n in zi.namelist() if n.lower().endswith(\".xml\")]\n",
    "\n",
    "    for xml_name in xmls:\n",
    "        with zi.open(xml_name) as f:\n",
    "            head = f.read(16384)\n",
    "            ts = parse_snapshot_ts_from_head(head)\n",
    "\n",
    "            if ts and (latest is None or ts > latest):\n",
    "                latest = ts\n",
    "        print(\"New Latest snapshot:\", latest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6c21b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVBG.086.01_BV000328202602040328000001945385434.xml 2026-02-04 22:45:23+00:00 header_ts\n"
     ]
    }
   ],
   "source": [
    "from ml_ettj26.domain.b3_PriceReport.parsing import pick_latest_xml\n",
    "zip_externo = zip_path[2]\n",
    "reader = NestedZipReader(zip_externo)\n",
    "\n",
    "with reader.open_inner_zip() as zi:\n",
    "    xml_names = [n for n in zi.namelist() if n.lower().endswith(\".xml\")]\n",
    "    pick = pick_latest_xml(zi, xml_names, head_bytes=64_000)\n",
    "\n",
    "print(pick.xml_name, pick.snapshot_dt, pick.method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddfbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DI1QuotesDaily(TradDt=datetime.datetime(2026, 2, 4, 0, 0, tzinfo=datetime.timezone.utc), TckrSymb='DI1N26', snapshot_ts_utc=datetime.datetime(2026, 2, 4, 22, 45, 23, tzinfo=datetime.timezone.utc), AdjstdQtTax=14.336, AdjstdQt=94872.95, BestBidPric=14.33, BestAskPric=14.335, LastPric=14.335, TradAvrgPric=14.34, MinPric=14.33, MaxPric=14.36, TradQty=3484, FinInstrmQty=310381, OpnIntrst=4171817, lineage_id='TEST_LINEAGE', ingestion_ts_utc=datetime.datetime(2026, 2, 22, 23, 55, 56, 872928, tzinfo=datetime.timezone.utc))\n"
     ]
    }
   ],
   "source": [
    "from ml_ettj26.domain.b3_PriceReport.zip_reader import NestedZipReader\n",
    "from ml_ettj26.domain.b3_PriceReport.parsing import iter_di1_quotes\n",
    "from ml_ettj26.domain.b3_PriceReport.parsing import pick_latest_xml\n",
    "from datetime import datetime, timezone\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "outer_zip =zip_path[2]\n",
    "reader = NestedZipReader(outer_zip)\n",
    "\n",
    "with reader.open_inner_zip() as zi:\n",
    "    xml_names = [n for n in zi.namelist() if n.endswith(\".xml\")]\n",
    "    pick = pick_latest_xml(zi, xml_names)\n",
    "\n",
    "    xml_name = pick.xml_name\n",
    "\n",
    "    snapshot_ts = pick.snapshot_dt or datetime.now(timezone.utc)\n",
    "    ingestion_ts = datetime.now(timezone.utc)\n",
    "    lineage_id = \"TEST_LINEAGE\"\n",
    "\n",
    "    # 🔹 Testando iter_di1_quotes (recomendado)\n",
    "    with zi.open(xml_name) as f:\n",
    "        for q in iter_di1_quotes(\n",
    "            f,\n",
    "            snapshot_ts_utc=snapshot_ts,\n",
    "            lineage_id=lineage_id,\n",
    "            ingestion_ts_utc=ingestion_ts,\n",
    "        ):\n",
    "            print(q)\n",
    "            break  # só primeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39904c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Criando um DataFrame de exemplo\n",
    "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': ['A', 'B', 'C']})\n",
    "# Salvando o DataFrame no formato Parquet\n",
    "#df.to_parquet(r'C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\\di1_instrument_master.parquet', engine='pyarrow', compression='snappy')\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Caminho\n",
    "path = Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Criar DataFrame vazio com schema correto\n",
    "df = pd.DataFrame({\n",
    "    \"TckrSymb\": pd.Series(dtype=\"string\"),\n",
    "    \"asset\": pd.Series(dtype=\"string\"),\n",
    "    \"contract_month_code\": pd.Series(dtype=\"string\"),\n",
    "    \"contract_year\": pd.Series(dtype=\"int64\"),\n",
    "    \"maturity_date\": pd.Series(dtype=\"datetime64[ns]\"),\n",
    "})\n",
    "\n",
    "# Salvar parquet vazio\n",
    "df.to_parquet(path / \"di1_instrument_master.parquet\", index=False)\n",
    "\n",
    "print(\"Seed criado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2210eba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 44 entries, 0 to 43\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   TckrSymb             44 non-null     str                \n",
      " 1   asset                44 non-null     str                \n",
      " 2   contract_month_code  44 non-null     str                \n",
      " 3   contract_year        44 non-null     int64              \n",
      " 4   maturity_date        44 non-null     datetime64[us, UTC]\n",
      "dtypes: datetime64[us, UTC](1), int64(1), str(3)\n",
      "memory usage: 2.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\\di1_instrument_master.parquet\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e5611e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   lineage_id        21 non-null     str                \n",
      " 1   outer_zip         21 non-null     str                \n",
      " 2   inner_zip         21 non-null     str                \n",
      " 3   xml_name          21 non-null     str                \n",
      " 4   snapshot_ts_utc   21 non-null     str                \n",
      " 5   hash_file         21 non-null     str                \n",
      " 6   ingestion_ts_utc  21 non-null     datetime64[us, UTC]\n",
      "dtypes: datetime64[us, UTC](1), str(6)\n",
      "memory usage: 8.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\\di1_lineage\\2026-01.parquet\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "09c253fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 880 entries, 0 to 879\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   TradDt            880 non-null    datetime64[us, UTC]\n",
      " 1   TckrSymb          880 non-null    str                \n",
      " 2   snapshot_ts_utc   880 non-null    datetime64[us, UTC]\n",
      " 3   AdjstdQtTax       880 non-null    float64            \n",
      " 4   AdjstdQt          880 non-null    float64            \n",
      " 5   BestBidPric       705 non-null    float64            \n",
      " 6   BestAskPric       702 non-null    float64            \n",
      " 7   LastPric          820 non-null    float64            \n",
      " 8   TradAvrgPric      820 non-null    float64            \n",
      " 9   MinPric           820 non-null    float64            \n",
      " 10  MaxPric           820 non-null    float64            \n",
      " 11  TradQty           820 non-null    float64            \n",
      " 12  FinInstrmQty      820 non-null    float64            \n",
      " 13  OpnIntrst         872 non-null    float64            \n",
      " 14  lineage_id        880 non-null    str                \n",
      " 15  ingestion_ts_utc  880 non-null    datetime64[us, UTC]\n",
      "dtypes: datetime64[us, UTC](3), float64(11), str(2)\n",
      "memory usage: 275.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\\di1_quotes_daily\\2026-01.parquet\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27d1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 2021-01\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\")\n",
    "PIPELINE = \"trusted_b3_di1\"\n",
    "\n",
    "def run_month(ym: str):\n",
    "    params = f\"b3_di1_range.start_month={ym},b3_di1_range.end_month={ym}\"\n",
    "    cmd = [sys.executable, \"-m\", \"kedro\", \"run\", \"--pipeline\", PIPELINE, \"--params\", params]\n",
    "\n",
    "    r = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(PROJECT_ROOT),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding=\"utf-8\",     # <- força UTF-8\n",
    "        errors=\"replace\",     # <- troca bytes inválidos por � ao invés de quebrar\n",
    "    )\n",
    "\n",
    "    if r.returncode != 0:\n",
    "        print(\"STDOUT:\\n\", r.stdout)\n",
    "        print(\"STDERR:\\n\", r.stderr)\n",
    "        raise RuntimeError(f\"Kedro falhou para {ym} (code {r.returncode})\")\n",
    "\n",
    "    print(f\"[OK] {ym}\")\n",
    "\n",
    "gatilho = True # <- cuidado: roda para todos os meses! \n",
    "if gatilho:\n",
    "    for year in range(2021, 2022): # <- Range de anos (inclusivo início, exclusivo fim)\n",
    "        for month in range(1, 2): # <- Range de meses (inclusivo início, exclusivo fim)\n",
    "            ym = f\"{year}-{month:02d}\"\n",
    "            run_month(ym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b14ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAD | PR210104_20210104.zip | PR210104.zip | BVBG.086.01_BV000328202101040328000002030310476.xml | mismatched tag: line 465115, column 14\n"
     ]
    }
   ],
   "source": [
    "#@'\n",
    "import os, re, zipfile, io, xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path(r\"c:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\")\n",
    "folder = root / \"data\" / \"01_raw\" / \"b3\" / \"PriceReport\"\n",
    "pat = re.compile(r\"_(\\d{8})\\.zip$\", re.I)\n",
    "\n",
    "bad = []\n",
    "for p in sorted(folder.glob(\"PR*_202101*.zip\")):\n",
    "    outer = p.name\n",
    "    try:\n",
    "        with zipfile.ZipFile(p, 'r') as zo:\n",
    "            inner_names = [n for n in zo.namelist() if n.lower().endswith('.zip')]\n",
    "            if not inner_names:\n",
    "                continue\n",
    "            with zo.open(inner_names[0]) as inner_bytes:\n",
    "                with zipfile.ZipFile(io.BytesIO(inner_bytes.read()), 'r') as zi:\n",
    "                    xmls = [n for n in zi.namelist() if n.lower().endswith('.xml')]\n",
    "                    if not xmls:\n",
    "                        continue\n",
    "                    xml_name = sorted(xmls)[-1]\n",
    "                    with zi.open(xml_name) as xf:\n",
    "                        try:\n",
    "                            for _ in ET.iterparse(xf, events=(\"end\",)):\n",
    "                                pass\n",
    "                        except ET.ParseError as e:\n",
    "                            bad.append((outer, inner_names[0], xml_name, str(e)))\n",
    "    except Exception as e:\n",
    "        bad.append((outer, '<outer>', '<outer>', f'{type(e).__name__}: {e}'))\n",
    "\n",
    "if not bad:\n",
    "    print('NO_PARSE_ERRORS')\n",
    "else:\n",
    "    for item in bad:\n",
    "        print('BAD', *item, sep=' | ')\n",
    "#'@ | uv run python -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1af61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465113:               <MaxTradLmt Ccy=\"ZAR\">999991</MaxTradLmt>\n",
      "465114:               <MinTradLmt Ccy=\"ZAR\">1</MinTradLmt>\n",
      "465115:             </FinInstrmAttrbts>\n",
      "465116:           </PricRpt>\n",
      "465117:         </Document>\n"
     ]
    }
   ],
   "source": [
    "#@'\n",
    "import zipfile, io\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(r\"c:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\b3\\PriceReport\\PR210104_20210104.zip\")\n",
    "with zipfile.ZipFile(p, 'r') as zo:\n",
    "    iname = [n for n in zo.namelist() if n.lower().endswith('.zip')][0]\n",
    "    with zo.open(iname) as ib:\n",
    "        with zipfile.ZipFile(io.BytesIO(ib.read()), 'r') as zi:\n",
    "            xname = 'BVBG.086.01_BV000328202101040328000002030310476.xml'\n",
    "            with zi.open(xname) as xf:\n",
    "                target = 465115\n",
    "                start = target - 2\n",
    "                end = target + 2\n",
    "                for i, raw in enumerate(xf, start=1):\n",
    "                    if i < start:\n",
    "                        continue\n",
    "                    if i > end:\n",
    "                        break\n",
    "                    line = raw.decode('utf-8', errors='replace').rstrip('\\n')\n",
    "                    print(f\"{i}: {line[:220]}\")\n",
    "#'@ | uv run python -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990494a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465035:                   <Prtry>8</Prtry>\n",
      "465036:                 </Tp>\n",
      "465037:               </OthrId>\n",
      "465038:               <PlcOfListg>\n",
      "465039:                 <MktIdrCd>BVMF</MktIdrCd>\n",
      "465040:               </PlcOfListg>\n",
      "465041:             </FinInstrmId>\n",
      "465042:             <TradDtls />\n",
      "465043:             <FinInstrmAttrbts>\n",
      "465044:               <OpnIntrst>56000</OpnIntrst>\n",
      "465045:             </FinInstrmAttrbts>\n",
      "465046:           </PricRpt>\n",
      "465047:         </Document>\n",
      "465048:       </BizGrp>\n",
      "465049:       <BizGrp>\n",
      "465050:         <AppHdr xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:iso:std:iso:20022:tech:xsd:head.001.001.01\">\n",
      "465051:           <BizMsgIdr>BV000328202101040328000002030260941</BizMsgIdr>\n",
      "465052:           <MsgDefIdr>BVMF.217.01</MsgDefIdr>\n",
      "465053:           <CreDt>2021-01-04T23:30:26Z</CreDt>\n",
      "465054:           <Fr>\n",
      "465055:             <OrgId>\n",
      "465056:               <Id>\n",
      "465057:                 <OrgId>\n",
      "465058:                   <Othr>\n",
      "465059:                     <Id>BVMF</Id>\n",
      "465060:                     <SchmeNm>\n",
      "465061:                       <Prtry>39</Prtry>\n",
      "465062:                     </SchmeNm>\n",
      "465063:                     <Issr>40</Issr>\n",
      "465064:                   </Othr>\n",
      "465065:                 </OrgId>\n",
      "465066:               </Id>\n",
      "465067:             </OrgId>\n",
      "465068:           </Fr>\n",
      "465069:           <To>\n",
      "465070:             <OrgId>\n",
      "465071:               <Id>\n",
      "465072:                 <OrgId>\n",
      "465073:                   <Othr>\n",
      "465074:                     <Id>PUBLIC</Id>\n",
      "465075:                     <SchmeNm>\n",
      "465076:                       <Prtry>39</Prtry>\n",
      "465077:                     </SchmeNm>\n",
      "465078:                     <Issr>40</Issr>\n",
      "465079:                   </Othr>\n",
      "465080:                 </OrgId>\n",
      "465081:               </Id>\n",
      "465082:             </OrgId>\n",
      "465083:           </To>\n",
      "465084:         </AppHdr>\n",
      "465085:         <Document xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:bvmf.217.01.xsd\">\n",
      "465086:           <PricRpt>\n",
      "465087:             <TradDt>\n",
      "465088:               <Dt>2021-01-04</Dt>\n",
      "465089:             </TradDt>\n",
      "465090:             <SctyId>\n",
      "465091:               <TckrSymb>AFSF21</TckrSymb>\n",
      "465092:             </SctyId>\n",
      "465093:             <FinInstrmId>\n",
      "465094:               <OthrId>\n",
      "465095:                 <Id>100000140396</Id>\n",
      "465096:                 <Tp>\n",
      "465097:                   <Prtry>8</Prtry>\n",
      "465098:                 </Tp>\n",
      "465099:               </OthrId>\n",
      "465100:               <PlcOfListg>\n",
      "465101:                 <MktIdrCd>BVMF</MktIdrCd>\n",
      "465102:               </PlcOfListg>\n",
      "465103:             </FinInstrmId>\n",
      "465104:             <TradDtls />\n",
      "465105:             <FinInstrmAttrbts>\n",
      "465106:               <OpnIntrst>160</OpnIntrst>\n",
      "465107:               <AdjstdQt Ccy=\"ZAR\">14605/AdjstdQt>\n",
      "465108:               <AdjstdQtStin>F</AdjstdQtStin>\n",
      "465109:               <PrvsAdjstdQt Ccy=\"ZAR\">14605</PrvsAdjstdQt>\n",
      "465110:               <PrvsAdjstdQtStin>F</PrvsAdjstdQtStin>\n",
      "465111:               <VartnPts Ccy=\"ZAR\">0</VartnPts>\n",
      "465112:               <AdjstdValCtrct Ccy=\"ZAR\">296.8356275</AdjstdValCtrct>\n",
      "465113:               <MaxTradLmt Ccy=\"ZAR\">999991</MaxTradLmt>\n",
      "465114:               <MinTradLmt Ccy=\"ZAR\">1</MinTradLmt>\n",
      "465115:             </FinInstrmAttrbts>\n",
      "465116:           </PricRpt>\n",
      "465117:         </Document>\n",
      "465118:       </BizGrp>\n",
      "465119:       <BizGrp>\n",
      "465120:         <AppHdr xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"urn:iso:std:iso:20022:tech:xsd:head.001.001.01\">\n",
      "465121:           <BizMsgIdr>BV000328202101040328000002030260941</BizMsgIdr>\n",
      "465122:           <MsgDefIdr>BVMF.217.01</MsgDefIdr>\n",
      "465123:           <CreDt>2021-01-04T23:30:26Z</CreDt>\n",
      "465124:           <Fr>\n",
      "465125:             <OrgId>\n",
      "465126:               <Id>\n",
      "465127:                 <OrgId>\n",
      "465128:                   <Othr>\n",
      "465129:                     <Id>BVMF</Id>\n",
      "465130:                     <SchmeNm>\n",
      "465131:                       <Prtry>39</Prtry>\n",
      "465132:                     </SchmeNm>\n",
      "465133:                     <Issr>40</Issr>\n",
      "465134:                   </Othr>\n",
      "465135:                 </OrgId>\n"
     ]
    }
   ],
   "source": [
    "import zipfile, io\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(r\"c:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\01_raw\\b3\\PriceReport\\PR210104_20210104.zip\")\n",
    "with zipfile.ZipFile(p, 'r') as zo:\n",
    "    iname = [n for n in zo.namelist() if n.lower().endswith('.zip')][0]\n",
    "    with zo.open(iname) as ib:\n",
    "        with zipfile.ZipFile(io.BytesIO(ib.read()), 'r') as zi:\n",
    "            xname = 'BVBG.086.01_BV000328202101040328000002030310476.xml'\n",
    "            with zi.open(xname) as xf:\n",
    "                target = 465115\n",
    "                start = target - 80\n",
    "                end = target + 20\n",
    "                for i, raw in enumerate(xf, start=1):\n",
    "                    if i < start:\n",
    "                        continue\n",
    "                    if i > end:\n",
    "                        break\n",
    "                    line = raw.decode('utf-8', errors='replace').rstrip('\\n')\n",
    "                    print(f\"{i}: {line}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a81c1688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-01-04 00:00:00+00:00', '2021-01-05 00:00:00+00:00',\n",
       " '2021-01-06 00:00:00+00:00', '2021-01-07 00:00:00+00:00',\n",
       " '2021-01-08 00:00:00+00:00', '2021-01-11 00:00:00+00:00',\n",
       " '2021-01-12 00:00:00+00:00', '2021-01-13 00:00:00+00:00',\n",
       " '2021-01-14 00:00:00+00:00', '2021-01-15 00:00:00+00:00',\n",
       " '2021-01-18 00:00:00+00:00', '2021-01-19 00:00:00+00:00',\n",
       " '2021-01-20 00:00:00+00:00', '2021-01-21 00:00:00+00:00',\n",
       " '2021-01-22 00:00:00+00:00', '2021-01-26 00:00:00+00:00',\n",
       " '2021-01-27 00:00:00+00:00', '2021-01-28 00:00:00+00:00',\n",
       " '2021-01-29 00:00:00+00:00']\n",
       "Length: 19, dtype: datetime64[us, UTC]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\b3\\di1_quotes_daily\\2021-01.parquet\")\n",
    "df[\"TradDt\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b29fcd",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e486bf",
   "metadata": {},
   "source": [
    "## Calendário : *ANBIMA*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14fc3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "holidays = pd.read_parquet(r'C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\calendars\\02_trusted\\ref\\anbima_holidays.parquet')\n",
    "bu_index = pd.read_parquet(r'C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\calendars\\02_trusted\\ref\\calendar_bd_index.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "76924c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1263 entries, 0 to 1262\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   cal_id            1263 non-null   str                \n",
      " 1   date              1263 non-null   datetime64[ms, UTC]\n",
      " 2   holiday_name      1263 non-null   str                \n",
      " 3   weekday           1263 non-null   int32              \n",
      " 4   ingestion_ts_utc  1263 non-null   str                \n",
      " 5   source_file_hash  1263 non-null   str                \n",
      " 6   pipeline_run_id   1263 non-null   str                \n",
      "dtypes: datetime64[ms, UTC](1), int32(1), str(5)\n",
      "memory usage: 214.4 KB\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 36159 entries, 0 to 36158\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   cal_id            36159 non-null  str                \n",
      " 1   date              36159 non-null  datetime64[ms, UTC]\n",
      " 2   weekday           36159 non-null  int32              \n",
      " 3   is_business_day   36159 non-null  bool               \n",
      " 4   bd_index          36159 non-null  int64              \n",
      " 5   holiday_name      1263 non-null   str                \n",
      " 6   ingestion_ts_utc  36159 non-null  str                \n",
      " 7   source_file_hash  36159 non-null  str                \n",
      " 8   pipeline_run_id   36159 non-null  str                \n",
      "dtypes: bool(1), datetime64[ms, UTC](1), int32(1), int64(1), str(5)\n",
      "memory usage: 5.7 MB\n",
      "None\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(holidays.info(), bu_index.info(), sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22e3baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 36159 entries, 0 to 36158\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   cal_id            36159 non-null  str                \n",
      " 1   date              36159 non-null  datetime64[ms, UTC]\n",
      " 2   weekday           36159 non-null  int32              \n",
      " 3   is_business_day   36159 non-null  bool               \n",
      " 4   bd_index          36159 non-null  int64              \n",
      " 5   holiday_name      0 non-null      str                \n",
      " 6   ingestion_ts_utc  36159 non-null  str                \n",
      " 7   source_file_hash  36159 non-null  str                \n",
      " 8   pipeline_run_id   36159 non-null  str                \n",
      "dtypes: bool(1), datetime64[ms, UTC](1), int32(1), int64(1), str(5)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "bu_index.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-ETTJ26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
