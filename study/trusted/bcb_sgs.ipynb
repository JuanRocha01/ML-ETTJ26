{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d03a90",
   "metadata": {},
   "source": [
    "# **Trusted** : BCB raw data\n",
    "\n",
    "A camada trusted como a primeira representação estruturada e validada dos dados após a ingestão bruta (raw). Ela transforma arquivos heterogêneos (JSON, CSV, XML, ZIP etc.) em datasets tabulares padronizados, tipados e auditáveis, mantendo fidelidade à fonte original.\n",
    "\n",
    "***Se o Raw é evidência, a Trusted é evidência organizada.***\n",
    "\n",
    "Ela ainda não aplica regras de negócio complexas ou integra múltiplas fontes — isso pertence às camadas seguintes (Refined, Feature, etc.). A Trusted apenas garante que os dados:\n",
    "\n",
    "- possuem tipos corretos\n",
    "- têm schema estável\n",
    "- são consistentes e reprocessáveis\n",
    "- mantêm rastreabilidade completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451206e8",
   "metadata": {},
   "source": [
    "## Raw Data: *SGS*\n",
    "\n",
    "### *1. Tipo e Estrutura*\n",
    "Os dados extraídos da SGS são até o momento especificamente as séries SELIC (432) e IPCA (433). Por definição esses são dados diários extraídos (para IPCA o BCB aplica um interpolação para retornar o variação percentual do dia) cujo o principal interesse é *data* e *valor*. Afim de preservar uma estrutura auditável também serão gerados campos que indiquem:\n",
    "\n",
    "- Data de Processamento (injestion)\n",
    "- Arquivo Raw que gerou aquele dados\n",
    "- Hash do conteúdo para governança, pois:\n",
    "    - Auditável permitindo reconstruir histórico, provar integridade e fazer reconciliação\n",
    "    - Caso reprocesse o mesmo período os dados não são reinseridos (indepotência)\n",
    "    - Detectar alteração silenciosa (Se houver alteração de dados antigos a coluna vai acusar)\n",
    "    - Unicidade Real; Pequenas variações de campo e formatação (como tipo) não impactam a base\n",
    "\n",
    "tornando assim os dados *raw* uma *tabela clean e auditável\". Com isso em mente podemos montar o schema desses dados como:\n",
    "\n",
    "**Raw:**\n",
    " data | valor |\n",
    "|:------------:|:-------:|\n",
    "| str | str |\n",
    "\n",
    "**Trusted**\n",
    "\n",
    "| series_id | ref_date | value | raw_file | raw_hash | record_hash | ijestioningestion_ts_utc |\n",
    "|:---------:|:--------:|:-----:|:--------:|:--------:|:-----------:|:------------------------:|\n",
    "| int | date | float | str | str | str | str |\n",
    "\n",
    "series_id e ref_date fornecem naturalmente uma chave única para a base de dados.\n",
    "\n",
    "#### *Classe Modelo*\n",
    "\n",
    "Como estamos falando de um processo fixo de injestão de dados que serão transformados em arquivos *.parquet* é interessenate construir uma classe fixa de formatação de dados não dependendo de pandas. Esse tipo de arquitetura é interessante inclusive pela restrição de flexbilidade do objeto gerando flexibilidade de código, já que seu futuramente pandas não for mais uma opção o domínio SgsPoint continua o mesmo, com controle de tipo e testabilidade.\n",
    "\n",
    "```python models.py\n",
    "@dataclass(frozen=True)\n",
    "class SgsPoint:\n",
    "    series_id: int\n",
    "    ref_date: date\n",
    "    value: Optional[float]  # pode ser None se vier vazio\n",
    "    raw_file: str\n",
    "    raw_hash: str\n",
    "    record_hash: str\n",
    "    ingestion_ts_utc: str \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfbde8",
   "metadata": {},
   "source": [
    "Apartir da forma que os arquivos JSON estão sendo salvos podemos facilmente extrair de qual série são aqueles dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60db0b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'433'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "path = Path(\"C:\\\\Users\\\\Dell\\\\OneDrive\\\\Documentos\\\\GitHub\\\\ML-ETTJ26\\\\data\\\\01_raw\\\\bcb\\\\sgs\\\\433_01-01-2000_31-12-2008.json\")\n",
    "\n",
    "stem = path.stem\n",
    "series_str = stem.split(\"_\", 1)[0]\n",
    "series_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350c2db",
   "metadata": {},
   "source": [
    "\n",
    "Com uma rápida olhada nos dados podemos perceber que as informações extaráidas da API está em uma lista de discionários onde ambas as chaves e valores são strings.\n",
    "\n",
    "```JSON\n",
    "[{'data': '01/01/2000', 'valor': '1.00'}, ...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba8dcdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': '01/01/2000', 'valor': '0.62'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    json_f = json.load(f)\n",
    "json_f[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c20abe",
   "metadata": {},
   "source": [
    "Antes de passar esses valores para trusted eles precisam então ser normalizados:\n",
    "- Data deve ser formato date, não string\n",
    "- Valor deve ser valor decimal com quantidade fixa de casas, não string \n",
    "\n",
    "(obs: float pode gerar comportamento indesejado em razão da base binária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9450e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2000, 1, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "s = json_f[0][\"data\"]\n",
    "datetime.strptime(s, \"%d/%m/%Y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fd3caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6200000000 0.62\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "s = json_f[0].get(\"valor\")\n",
    "s = str(s).strip()\n",
    "s = Decimal(s)\n",
    "vq = s.quantize(Decimal(\"0.0000000001\"), rounding=ROUND_HALF_UP)\n",
    "print(vq, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0e4a3",
   "metadata": {},
   "source": [
    "Tranquilamente conseguimos Gerar agora os valores hash com a segurança de comportamento maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "599d1f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'072692bcfd6ededdac1377bf9cab985900fca426ef5d8543c6d9a7cdc779fb24'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "series_id = int(series_str)\n",
    "ref_date = datetime.strptime(json_f[0][\"data\"], \"%d/%m/%Y\").date()\n",
    "value_dec = vq\n",
    "\n",
    "payload = f\"{series_id}|{ref_date.isoformat()}|{value_dec}\"\n",
    "\n",
    "record_hash = hashlib.sha256(payload.encode(\"utf-8\")).hexdigest()\n",
    "record_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f602d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2064cccd061cb5ed9f8747e42c3cbbea8637b9542f78a6146547c9c8674f67ef'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = hashlib.sha256()\n",
    "with path.open(\"rb\") as f:\n",
    "    \n",
    "    for chunk in iter(lambda: f.read(1024 * 1024), b\"\"):\n",
    "        h.update(chunk)\n",
    "h.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8eef87fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2026-02-16T21:29:27+00:00'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "ingestion_ts_utc = datetime.now(timezone.utc).replace(microsecond=0).isoformat()\n",
    "ingestion_ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59ec24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sgs_t = pd.read_parquet(r\"C:\\Users\\Dell\\OneDrive\\Documentos\\GitHub\\ML-ETTJ26\\data\\02_trusted\\bcb\\sgs_daily\\sgs_daily.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84379bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([432, 433])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgs_t['series_id'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
